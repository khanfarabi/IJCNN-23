{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFjZxJahMxh8"
      },
      "source": [
        "# Package Installation "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fg-8mLgmFAL"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "def inst():\n",
        "        !pip install -U sentence-transformers\n",
        "        !pip install sentence_transformers\n",
        "        !pip install transformers\n",
        "        !pip install datasets\n",
        "        !pip install stop_words\n",
        "        #!pip install flair \n",
        "        !pip install scipy \n",
        "        !pip install https://github.com/scikit-learn-contrib/scikit-learn-extra/archive/master.zip\n",
        "        !pip install git+https://github.com/PrithivirajDamodaran/Alt-ZSC.git\n",
        "        !pip install git+https://github.com/neuml/txtai\n",
        "inst()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RLLYfXz_U7AZ"
      },
      "source": [
        "# Data Pre-Processing and filter out 900 texts that have more than one class labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "366NoOounkh-"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286,
          "referenced_widgets": [
            "652ac484380344848a6b01c2fa53a3d5",
            "ac407ec0f24c4bf796d66c24f165fdbd",
            "bbd6653298254629b44a406ccf3e5060",
            "9b6a74b10f0e4426825e472d7822a0c6",
            "e40178f8553b41d19989b256da9c12f9",
            "94317af58f4c44f29ca0c2c78e451712",
            "6c9e5ba2c3c54c3b9d2d641aa1f9d715",
            "393b862585af465da9592e0a544eae17",
            "c84ab686455c44e3a6dbdbd65a32c4b6",
            "be2d87b3fb2946f699c68b668637b7a9",
            "2c504b12b8fc4a89941acc3a33389a31",
            "f6cb81df58b143148db4176d980c12fb",
            "3b352707985f4dff9a66a97b002c3973",
            "3e3e5dcb16a249b3b1464412df89ceb8",
            "8c34e36d9414406898867bc3968951ed",
            "e79f5a5b54e24d9e9283374f6a603fe7",
            "408d048a89e547818ee8d6fa10d0ac05",
            "ac5a86a33b9745279e09d6657edb826a",
            "986976bf69f6455a80d1640d2a5729e3",
            "5fe6a1a0fc2744faa0d706e4468bb652",
            "c1778f5c0c6f4649a0458bbad31feba7",
            "ff4565e1b760425bb81dd1b09881657f",
            "56c784471e634b979f00de1bff554610",
            "c6f21ef4f778496d8f6566ffc436852c",
            "2abc2eacb8ce4523bdc9cd6a936ef1a4",
            "b63a2d8d8bf34aff82774dc8eaec84a5",
            "8b2741f3fc2f4137a09a77efd88888cf",
            "913717e56f594b36ad999e0edd0ea827",
            "b997371f85e04791a48ba803df1812ec",
            "0066609e5e8e4612b31f6810100e35dd",
            "5a13bde675b34fbb82f3639648bf410f",
            "205de46e95fe49f9a441a42d51fe38b7",
            "2e45038cbad140ee888ab0354e233cbe",
            "41a0391bade84f6ba98b3df65e9703e0",
            "08f3aa45f2fe47fb89824875f61d64b2",
            "2152d97a76024bea802421eb3873b244",
            "ed07b250f6944a5eb6921cc5ae16dbd2",
            "c14776fd15d046c89bc7c8adc578387b",
            "b64c193c8e5c47759154fdde7a93e620",
            "b59943ec6a664dba966c0cd5d887aff3",
            "86b2748dd5844bdea170edb37f978e8d",
            "f7c4998876d14184bb8c55d54ec36cf6",
            "a001fb3429f34d3cafa0feb0019713aa",
            "2d1e98ecea614c9daaf75f41f9eab1ae",
            "7f4cdfb52ff84cd79ae9507d912f6fb6",
            "ab557e8a521947688863f14c46435a97",
            "df8ddaaca916442c8c58c7e064d0113d",
            "94501ff6199048ef9311e6e9dbffef3c",
            "113c5d858b4e43b3bd999c608849fec3",
            "995f42023d0b44ce8ef5b78c72587b38",
            "f667f29fb62c4b758d1830d1f7630945",
            "835c222f33794d91a868088942708611",
            "99af91501f6d43d89a1f89cff78e6ede",
            "100a8bd7175c4c64bd11a72f13cebee7",
            "1ec9d34cc0ab4f889b2b19c6e30a35ea",
            "b6b338d8aa4241d09890f0da7e6617b4",
            "2a8e9e0049444da293208f3c13080c9a",
            "435237f915b94d549c740db895a101ec",
            "2222888c063a4295b9ca502bfee2bfcc",
            "bce5481804084365a6ed873c6bf0b302",
            "63f32c8cb2254759bd45d51a37db5c0c",
            "42cd1a1c412c4bd29e207de33e40f387",
            "c3b4372cdbff4181b7b38317ef90e87b",
            "6aab97987dd94255b75f0fa2198b75a5",
            "1c397df2a8a44b63bbdd5746d473f161",
            "7ea9f7871e28439f8b6cbece3bd4f8ff",
            "15eb737e98e644aea0860430a87b89a2",
            "e750d2c0ac8b4f97af200bab5cb00a9f",
            "405882e92b2d4c67a9ab73e7137ae0f4",
            "7bb95a7a28a147ed9c5f6724087a1831",
            "5c9e2c1ea5fd4e1f8662ed9b5c4294e4",
            "c9f5650fbe48497f98f6466dafa0aacc",
            "10836d1772014617bae7c9f7167307dd",
            "6872183f31934ce9af84571ef3bc04df",
            "42a2589c6b904374ba3cc147de8c7281",
            "9ef344e7d5204825ac70ce5e33ccf3da",
            "8000ead497df4626a76ad71aadb7e31f"
          ]
        },
        "id": "U-WVaNIPnkmR",
        "outputId": "503ce0b1-6591-4136-a5de-5290f7d0357f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.17k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "652ac484380344848a6b01c2fa53a3d5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading metadata:   0%|          | 0.00/2.37k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6cb81df58b143148db4176d980c12fb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset reuters21578/ModApte (download: 7.77 MiB, generated: 12.48 MiB, post-processed: Unknown size, total: 20.25 MiB) to /root/.cache/huggingface/datasets/reuters21578/ModApte/1.0.0/98a2ad6a0242627562db83992f9625261854c40a88619322596153a5a16a206c...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading data:   0%|          | 0.00/8.15M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56c784471e634b979f00de1bff554610"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/3299 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "41a0391bade84f6ba98b3df65e9703e0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating train split:   0%|          | 0/9603 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f4cdfb52ff84cd79ae9507d912f6fb6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating unused split:   0%|          | 0/722 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b6b338d8aa4241d09890f0da7e6617b4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset reuters21578 downloaded and prepared to /root/.cache/huggingface/datasets/reuters21578/ModApte/1.0.0/98a2ad6a0242627562db83992f9625261854c40a88619322596153a5a16a206c. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "15eb737e98e644aea0860430a87b89a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "# Data Preprocessing to retieve the texts with the multiple labels\n",
        "from datasets import load_dataset\n",
        "from collections import defaultdict\n",
        "import re\n",
        "import random\n",
        "import numpy as np\n",
        "import operator\n",
        "import matplotlib.pyplot as plt\n",
        "#from transformers import pipeline\n",
        "from pylab import rcParams\n",
        "import sys \n",
        "import nltk\n",
        "import re\n",
        "nltk.download('punkt')\n",
        "import csv\n",
        "import pandas as pd\n",
        "import sys\n",
        "samelocation=defaultdict(list)\n",
        "\n",
        "reuters= load_dataset('reuters21578', 'ModApte')\n",
        "\n",
        "random.seed(1)\n",
        "\n",
        "def clean(label):\n",
        "    label = re.sub(\"([a-z])([A-Z])\", \"\\\\1 \\\\2\", label)\n",
        "    label = label.replace(\"_\", \" \")\n",
        "    return label\n",
        "\n",
        "\n",
        "def sample_test_data(texts,  labels, title, size):\n",
        "    data = list(zip(texts, labels,title))\n",
        "    data = [item for item in data if len(item[0]) > 0]\n",
        "    random.shuffle(data)\n",
        "    texts, labels,title = zip(*data)\n",
        "    return texts[:size], labels[:size], title[:size],texts[size:], labels[size:]\n",
        "reuters_train_texts, reuters_train_labels,title, _, _ = sample_test_data(reuters['train'], reuters['train']['topics'],reuters['train']['places'], 50000)\n",
        "#reuters_train_texts, reuters_train_labels,labels, _ = sample_test_data(reuters['train'], reuters['train']['topics'],reuters['train']['places'], 50000)\n",
        "#labels,_ = sample_test_data( reuters['train']['places'], 50000)\n",
        "txt_place={}\n",
        "place_tx=[]\n",
        "for t in title:\n",
        "    for kk in t:\n",
        "        place_tx.append(kk)\n",
        "same_tp=[]\n",
        "for hh in reuters_train_labels:\n",
        "    for kk in hh:\n",
        "       same_tp.append(kk)\n",
        "sm_topic=defaultdict(list)\n",
        "txt=[]\n",
        "\n",
        "import nltk\n",
        "nltk.download('wordnet')\n",
        "import nltk\n",
        "from stop_words import get_stop_words\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "stop_words = list(get_stop_words('en'))         #Have around 900 stopwords\n",
        "nltk_words = list(stopwords.words('english'))   #Have around 150 stopwords\n",
        "stop_words.extend(nltk_words)\n",
        "rttext_tag={}\n",
        "label_class=[]\n",
        "WORDS_ev={}\n",
        "sintag={}\n",
        "eid_maps={}\n",
        "eid_mapm={}\n",
        "rid=0\n",
        "rd_txt={}\n",
        "txt_rd={}\n",
        "#\n",
        "rttext_tags={}\n",
        "label_classs=[]\n",
        "WORDS_evs={}\n",
        "sintags={}\n",
        "eid_mapss={}\n",
        "eid_mapms={}\n",
        "rids=0\n",
        "rd_txts={}\n",
        "txt_rds={}\n",
        "\n",
        "for hh in range(len(reuters_train_labels)):\n",
        "  if len(reuters_train_labels[hh])>0 and len(reuters_train_texts[hh]['text'].split())>0:\n",
        "                  zz=reuters_train_labels[hh]\n",
        "                  #print(title[hh])\n",
        "                  #sys.exit()\n",
        "                  #print(\"text\"+\"\\n\")\n",
        "                  if len(zz)>1 and len(zz)<=3:\n",
        "                          vcc=0\n",
        "                          jj=re.sub('\\s+(a|an|and|the)(\\s+)', '\\2',reuters_train_texts[hh]['text'])\n",
        "                          from nltk.tokenize import word_tokenize\n",
        "                          tokens = word_tokenize(jj)\n",
        "                          # convert to lower case\n",
        "                          tokens = [w.lower() for w in tokens]\n",
        "                          # remove punctuation from each word\n",
        "                          import string\n",
        "                          table = str.maketrans('', '', string.punctuation)\n",
        "                          stripped = [w.translate(table) for w in tokens]\n",
        "                          # remove remaining tokens that are not alphabetic\n",
        "                          words = [word for word in stripped if word.isalpha()]\n",
        "                          # filter out stop words\n",
        "                          from nltk.corpus import stopwords\n",
        "                          stop_words = set(stopwords.words('english'))\n",
        "                          words = [w for w in words if not w in stop_words and len(w)>=3]\n",
        "                          wrd=[]\n",
        "                          sz=''\n",
        "                          for k in words:\n",
        "                             # if vcc<150:\n",
        "                                wrd.append(k)\n",
        "                                vcc=vcc+1\n",
        "                          #rttext_tag[wrd]=zz[0]\n",
        "                          if len(wrd)>=2:\n",
        "                              WORDS_ev[rid]=wrd\n",
        "                              #rid=rid+1\n",
        "                              for vv in wrd:\n",
        "                                if vv!='reuter':\n",
        "                                    sz=sz+vv+\" \"\n",
        "                            #print(zz,sz)\n",
        "                              for kk in zz:\n",
        "                                if kk not in label_class:\n",
        "                                    label_class.append(kk)\n",
        "                              rttext_tag[sz]=zz\n",
        "                              txt_place[sz]=title[hh]\n",
        "                              samelocation[place_tx[hh]].append(sz)\n",
        "                              sm_topic[same_tp[hh]].append(rid)\n",
        "                              sintag[sz]=zz[0:1]\n",
        "                              eid_maps[rid]=zz[0:1]\n",
        "                              eid_mapm[rid]=zz\n",
        "                              rd_txt[rid]=sz\n",
        "                              txt_rd[sz]=rid\n",
        "                              rid=rid+1\n",
        "                          #print(reuters_train_texts[hh]['text'].split())\n",
        "                          #txt.append(reuters_train_texts[hh]['text'])\n",
        "                          #print(\"\\n\\n\")\n",
        "                  elif len(zz)==1:\n",
        "                                        vcc=0\n",
        "                                        jj=re.sub('\\s+(a|an|and|the)(\\s+)', '\\2',reuters_train_texts[hh]['text'])\n",
        "                                        from nltk.tokenize import word_tokenize\n",
        "                                        tokens = word_tokenize(jj)\n",
        "                                        # convert to lower case\n",
        "                                        tokens = [w.lower() for w in tokens]\n",
        "                                        # remove punctuation from each word\n",
        "                                        import string\n",
        "                                        table = str.maketrans('', '', string.punctuation)\n",
        "                                        stripped = [w.translate(table) for w in tokens]\n",
        "                                        # remove remaining tokens that are not alphabetic\n",
        "                                        words = [word for word in stripped if word.isalpha()]\n",
        "                                        # filter out stop words\n",
        "                                        from nltk.corpus import stopwords\n",
        "                                        stop_words = set(stopwords.words('english'))\n",
        "                                        words = [w for w in words if not w in stop_words and len(w)>=4]\n",
        "                                        wrd=[]\n",
        "                                        sz=''\n",
        "                                        for k in words:\n",
        "                                            if vcc<150:\n",
        "                                                wrd.append(k)\n",
        "                                                vcc=vcc+1\n",
        "                                        #rttext_tag[wrd]=zz[0]\n",
        "                                        if len(wrd)>=5:\n",
        "                                            WORDS_evs[rid]=wrd\n",
        "                                            #rid=rid+1\n",
        "                                            for vv in wrd:\n",
        "                                                if vv!='reuter':\n",
        "                                                    sz=sz+vv+\" \"\n",
        "                                            #print(zz,sz)\n",
        "                                            for kk in zz:\n",
        "                                                if kk not in label_classs:\n",
        "                                                    label_classs.append(kk)\n",
        "                                            rttext_tags[sz]=zz\n",
        "                                            sintags[sz]=zz#[0:1]\n",
        "                                            eid_mapss[rid]=zz#[0:1]\n",
        "                                            eid_mapms[rid]=zz\n",
        "                                            rd_txts[rid]=sz\n",
        "                                            txt_rds[sz]=rid\n",
        "                                            rids=rids+1\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "for tt in txt_place:\n",
        "    pass#print\n",
        "rttext_tag2=rttext_tag\n",
        "#rttext_tagh1=rttext_tag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HRzSsrg0v-a0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjpNDr3ZbqL6",
        "outputId": "86bcbe62-3f72-4196-91b6-26696d55c38c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90\n"
          ]
        }
      ],
      "source": [
        "# Unique Tag list Filtering: Here we get the list of the unique classes\n",
        "tagu=[]\n",
        "tagu1=[]\n",
        "stt=[]\n",
        "sent=[]\n",
        "relation_sent=[]\n",
        "for  sz in rttext_tag2:\n",
        "           s=''\n",
        "           gh=[]\n",
        "           for vb in rttext_tag2[sz]:\n",
        "               #if vb not in stt:\n",
        "                  # s=str(vb)+\" \"+sz\n",
        "                   #if vb not in tagu1:\n",
        "                       #gh.append(vb)\n",
        "                       #tagu1.append(vb)\n",
        "                   #gh.append(sz)\n",
        "                   s=s+str(vb)+\" \"+str(sz)+\" \"\n",
        "                   relation_sent.append(s)\n",
        "                   if vb not in gh:\n",
        "                        gh.append(vb)\n",
        "                   if vb not in stt:\n",
        "                        stt.append(vb)\n",
        "                   vb1=sz.split()\n",
        "                   for zx in vb1:\n",
        "                        if zx not in gh:\n",
        "                            gh.append(zx)\n",
        "                   sent.append(gh)\n",
        "                   \n",
        "ds=set(stt)\n",
        "for kk in ds:\n",
        "    tagu.append(kk)\n",
        "print(len(tagu))\n",
        "for tt in tagu:\n",
        "    pass"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BqEtyCODcGs5"
      },
      "source": [
        "# Random Approach where we choose 100 texts randomly"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6jOoltBcN2B"
      },
      "outputs": [],
      "source": [
        "#\n",
        "# Assigning original tags and texts\n",
        "rttext_tagh1=rttext_tag2\n",
        "truhh=tagu\n",
        "print(len(rttext_tagh1),len(truhh))\n",
        "#RANDOM SELECTION of 100 texts\n",
        "def tagcls_only():  \n",
        "                    rttext_tagh={}\n",
        "                    mptxt={}\n",
        "                    rttag={}\n",
        "                    allid=[]\n",
        "                    truhh=[]\n",
        "                    vbb=[]\n",
        "                    for kk in rttext_tagh1:\n",
        "                        if txt_rd[str(kk)] not in allid:\n",
        "                            allid.append(txt_rd[str(kk)])\n",
        "\n",
        "                    vz=0\n",
        "                    for jj in range(0,115):\n",
        "                        bb=random.choice(allid)\n",
        "                        if (bb):\n",
        "                            vz=vz+1\n",
        "                            if  len(rttext_tagh)<100:\n",
        "                                rttext_tagh[rd_txt[bb]]=rttext_tagh1[rd_txt[bb]]\n",
        "\n",
        "             \n",
        "                    for tt in rttext_tagh:\n",
        "                        for kkk in rttext_tagh[tt]:\n",
        "                            if kkk not in  vbb:\n",
        "                                vbb.append(kkk)\n",
        "\n",
        "                    ss=set(vbb)\n",
        "                    #truhh=[]\n",
        "                    #rttext_tagh={}\n",
        "\n",
        "                    for vv in ss:\n",
        "                        truhh.append( vv)\n",
        "\n",
        "                    print(len(rttext_tagh),len(truhh))\n",
        "                    \n",
        "                    #Accuracy Computation\n",
        "\n",
        "                    #multi tag\n",
        "\n",
        "                    from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "                    import numpy as np\n",
        "                    import operator\n",
        "                    import matplotlib.pyplot as plt\n",
        "                    from transformers import pipeline\n",
        "                    from pylab import rcParams\n",
        "                    import sys \n",
        "                    import nltk\n",
        "                    import re\n",
        "                    import operator\n",
        "                    #from AltZSC import ZeroShotTextClassification\n",
        "\n",
        "                    #zstc = ZeroShotTextClassification()\n",
        "                    #from transformers_interpret import ZeroShotClassificationExplainer\n",
        "                    zero_shot_classifier = pipeline(\"zero-shot-classification\")#,model='facebook/bart-large-mnli')#,model='roberta-large-mnli')#model='facebook/bart-large-mnli')#,model='Recognai/zeroshot_selectra_medium')#,model='facebook/bart-large-mnli')\n",
        "                    #tokenizer = AutoTokenizer.from_pretrained(\"Recognai/zeroshot_selectra_medium\")#(\"facebook/bart-base-mnli\")#(\"Recognai/zeroshot_selectra_medium\")\n",
        "                    #model = AutoModelForSequenceClassification.from_pretrained(\"Recognai/zeroshot_selectra_medium\")#(\"facebook/bart-base-mnli\")#(\"Recognai/zeroshot_selectra_medium\")\n",
        "                    #zero_shot_explainer = ZeroShotClassificationExplainer(model, tokenizer)\n",
        "                    # creating embedding of the relational texts\n",
        "                    from sentence_transformers import SentenceTransformer\n",
        "                    from sklearn.cluster import KMeans\n",
        "                    import sys\n",
        "                    from sentence_transformers import SentenceTransformer\n",
        "                    from sklearn.cluster import AgglomerativeClustering\n",
        "                    import numpy as np\n",
        "                    from sentence_transformers import SentenceTransformer\n",
        "                    from sklearn.cluster import KMeans\n",
        "                    from sentence_transformers import SentenceTransformer\n",
        "                    from sklearn.cluster import AgglomerativeClustering\n",
        "                    import numpy as np\n",
        "                    import operator\n",
        "                    from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
        "                    import sys\n",
        "                    from scipy import spatial\n",
        "                    from sklearn_extra.cluster import KMedoids\n",
        "                    import numpy as np\n",
        "                    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "                    from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
        "\n",
        "                    cn=0\n",
        "                    txt_lbp={}\n",
        "                    ocl_di={}\n",
        "                    pred_l={}\n",
        "                    ocl_dia={}\n",
        "                    pred_lnk={}\n",
        "                    ocl_dnk={}\n",
        "                    pred_tk={}\n",
        "                    ocl_tk={}\n",
        "                    all_txt_label_score={}\n",
        "                    all_txt_label_rank={}\n",
        "                    def get_relational_embedding(s):\n",
        "                            corpus=[]\n",
        "                            s1=''\n",
        "                            for kk in samelocation:\n",
        "                                cc=0\n",
        "                                #for kj in samelocation[kk]:\n",
        "                                if s in samelocation[kk]: \n",
        "                                    for kj in samelocation[kk]:\n",
        "                                        corpus.append(kj)\n",
        "                                        s1=s1+kj+\" \"\n",
        "                                    # cc=cc+1\n",
        "                            embedder = SentenceTransformer('all-MiniLM-L12-v2')\n",
        "                            corpus_embeddings = embedder.encode(corpus)\n",
        "                            return corpus_embeddings,corpus,s1\n",
        "\n",
        "                    # Zero-shot Classification\n",
        "                    #from AltZSC import ZeroShotTextClassification\n",
        "\n",
        "                    #zstc = ZeroShotTextClassification()\n",
        "                    def review_explain(text):\n",
        "                           # corpus_embeddings,corpus,s1=get_relational_embedding(text)\n",
        "                            #zero_shot_classifier = pipeline(\"zero-shot-classification\")#.preprocess(corpus)#.transform(corpus)#.save_pretrained(corpus_embeddings)#,corpus_embeddings)\n",
        "                        \n",
        "                            result = zero_shot_classifier(sequences =text,candidate_labels =truhh,multi_label=True)\n",
        "                            #zero_shot_classifier(sequences =t,candidate_labels =truhh,multi_label=False)\n",
        "                            #preds = zstc(text=text,candidate_labels=truhh, multi_label=True,)\n",
        "                            return result['labels'],result['scores']\n",
        "                            #return list(preds['labels']),list(preds['scores'])\n",
        "\n",
        "                    \n",
        "                    for tt in rttext_tagh:\n",
        "                       # import sys\n",
        "                        #print(len(rttext_tagh[tt]))\n",
        "                        #sys.exit()\n",
        "                        mpd={}\n",
        "                        nlb=[]\n",
        "                        mpd_nk={}\n",
        "                        mpd_tk={}\n",
        "                        nlb_tk=[]\n",
        "                        nlb_nk=[]\n",
        "                        rn={}\n",
        "                        rsc={}\n",
        "                        try:\n",
        "                            clas,score= review_explain(tt)\n",
        "                        except:\n",
        "                            continue\n",
        "                    \n",
        "                        for bb in range(0,len(clas)):\n",
        "                            rsc[clas[bb]]=score[bb]\n",
        "                        for bb in range(0,len(clas)):\n",
        "                            rn[clas[bb]]=bb+1\n",
        "                        all_txt_label_score[tt]=rsc\n",
        "                        all_txt_label_rank[tt]=rn\n",
        "                        for k1 in rttext_tagh[tt]:\n",
        "                                for t3 in range(0,len(clas)):\n",
        "                                    if str(clas[t3])==str(k1):\n",
        "                                        mpd[k1]=score[t3]\n",
        "                        for k1 in rttext_tagh[tt]:\n",
        "                                for t3 in range(0,len(clas)):\n",
        "                                    if str(clas[t3])!=str(k1):\n",
        "                                        if score[t3]>0.5:\n",
        "                                            mpd_nk[k1]=score[t3]\n",
        "                        for k1 in rttext_tagh[tt]:\n",
        "                                for t3 in range(0,len(clas)):\n",
        "                                    if str(clas[t3])==str(k1):\n",
        "                                        if score[t3]>0.5:\n",
        "                                            mpd_tk[k1]=score[t3]\n",
        "                        \n",
        "                        dd=sorted(mpd.items(), key=operator.itemgetter(1),reverse=True)\n",
        "                        dd1=sorted(mpd_nk.items(), key=operator.itemgetter(1),reverse=True)\n",
        "                        dd2=sorted(mpd_tk.items(), key=operator.itemgetter(1),reverse=True)\n",
        "                        \n",
        "                        for zz in dd:\n",
        "                            nlb.append(zz[0])\n",
        "                        for zz1 in dd1:\n",
        "                            nlb_nk.append(zz1[0])\n",
        "                        for zz2 in dd2:\n",
        "                            nlb_tk.append(zz2[0])\n",
        "                        \n",
        "                        pred_lnk[tt]=nlb_nk #ranked list of the non-original labels has pribability greater than 50%\n",
        "                        pred_tk[tt]=nlb_tk#ranked list of the original labels has pribability greater than and equal 90% and appear in top N labels\n",
        "                        ocl_di[tt]=nlb[0:1]#single label with the highest score of the original label\n",
        "                        ocl_dia[tt]=nlb#ranked list of the original label\n",
        "                        \n",
        "\n",
        "                        txt_lbp[tt]=clas[0:10]\n",
        "                        pred_l[tt]=clas\n",
        "                    \n",
        "\n",
        "                    '''\n",
        "                    Comparing average rank of the predicted original labels with that of it ideal rank positon\n",
        "                    Coounting the number of non-original labels that have higher probability scores than that of original labels per text\n",
        "\n",
        "                    '''\n",
        "                    # average rank\n",
        "                    ccc=0\n",
        "                    KK=3 # number of top predicted non-original labels\n",
        "\n",
        "                    per_txt_ori_rank_cmp={}\n",
        "                    per_txt_ori_score_avg={}\n",
        "                    per_txt_nonori_rank_cmp={}\n",
        "                    per_txt_nonori_pred_rank_avg={}\n",
        "                    per_txt_nonori_ori_rank_avg={}\n",
        "                    per_txt_nonori_score_avg={}\n",
        "                    per_txt_ori_pred_rank_avg={}\n",
        "                    per_txt_ori_ori_rank_avg={}\n",
        "                    per_txt_nonori_top_n={}\n",
        "\n",
        "                    #import sys\n",
        "                    #print(len(all_txt_label_score))\n",
        "                   # sys.exit()\n",
        "                    for v in all_txt_label_score:\n",
        "                      if v in rttext_tagh:\n",
        "                        #import sys\n",
        "                        #print(len(rttext_tagh[v]))\n",
        "                        #sys.exit()\n",
        "                        orn=(len(rttext_tagh[v])+1)/2 # Ideal average rank position\n",
        "                        s=0\n",
        "                        sc=0\n",
        "                        cz=0\n",
        "                        nr=[]\n",
        "                        sno=0\n",
        "                        snosc=0\n",
        "                        for kz in all_txt_label_rank[v]:\n",
        "                            if kz not in rttext_tagh[v]:\n",
        "                                if cz<KK:\n",
        "                                        if kz not in nr:\n",
        "                                                nr.append(kz)\n",
        "                                                #print(kz,rttext_tagu[v],all_txt_label_rank[v][kz],all_txt_label_score[v][kz])\n",
        "                                                sno=sno+float(all_txt_label_rank[v][kz])\n",
        "                                                snosc=snosc+float(all_txt_label_score[v][kz])\n",
        "                                                cz=cz+1\n",
        "                        #print(\"\\n\")\n",
        "                        per_txt_nonori_top_n[v]=nr\n",
        "                        per_txt_nonori_rank_cmp[v]=sno/KK\n",
        "                        per_txt_nonori_score_avg[v]=snosc/KK\n",
        "\n",
        "                        for kz in all_txt_label_rank[v]:\n",
        "                            if kz in rttext_tagh[v]:\n",
        "                                s=s+float(all_txt_label_rank[v][kz])\n",
        "                                sc=sc+float(all_txt_label_score[v][kz])\n",
        "                        #import sys\n",
        "                        #print(len(rttext_tagh[v]))\n",
        "                        #sys.exit()\n",
        "                       # try:\n",
        "                        prn=s/len(rttext_tagh[v])\n",
        "                        per_txt_ori_score_avg[v]=sc/len(rttext_tagh[v])\n",
        "                        per_txt_ori_pred_rank_avg[v]=prn\n",
        "                        per_txt_ori_ori_rank_avg[v]=orn\n",
        "                        # print(prn)\n",
        "                        dif=abs(prn-orn)\n",
        "                        per_txt_ori_rank_cmp[v]=dif\n",
        "                        #except:\n",
        "                            #continue\n",
        "                        if dif<=0.0:\n",
        "                            ccc=ccc+1\n",
        "                    print(\"Number of texts where the position of the original labels preserved after prediction\")\n",
        "                    print(ccc)\n",
        "                    print(\"Percentage of texts where the position of the original labels preserved after prediction\")\n",
        "                    print(ccc/len(txt_lbp))\n",
        "\n",
        "\n",
        "                    # average scores\n",
        "\n",
        "                    vvv=0\n",
        "                    for jj in per_txt_ori_score_avg:\n",
        "                        if per_txt_nonori_score_avg[jj]>per_txt_ori_score_avg[jj]:\n",
        "                                    vvv=vvv+1\n",
        "\n",
        "                    print(\"Number of non-original labels have higher prediction acores than original labels after prediction\")\n",
        "                                \n",
        "                    print(vvv)\n",
        "\n",
        "                    '''\n",
        "                    Accuracy for the clustered labels\n",
        "                    '''\n",
        "                    #accuracy of multi-level classification with k-means clustering\n",
        "                    correct_txt_true_pred=[]\n",
        "                    def topps(n):\n",
        "                                cc=0\n",
        "                                vb1=0\n",
        "                                for tt in txt_lbp:\n",
        "                                        #if vb1 < 1000:\n",
        "                                                #vb1=vb1+1 \n",
        "                                                try:\n",
        "                                                    for vb in txt_lbp[tt][0:n]:\n",
        "                                                            #print(rttext_tagh[tt][0],vb)\n",
        "                                                            if vb in rttext_tagh[tt][0:n]:\n",
        "                                                            #if str(vb) ==str(rttext_tagh[tt][0]):\n",
        "                                                                cc=cc+1\n",
        "                                                                if tt not in correct_txt_true_pred:\n",
        "                                                                            correct_txt_true_pred.append(tt)\n",
        "                                                                break\n",
        "                                                            else:\n",
        "                                                                continue\n",
        "\n",
        "                                                except:\n",
        "                                                    continue\n",
        "                                                \n",
        "                                #txt_lbp\n",
        "                                print(\"Top_\"+str(n)+ \" Prediction Score: \")\n",
        "                                print(cc/len(txt_lbp))\n",
        "                                ac=cc/len(txt_lbp)\n",
        "                                return ac\n",
        "                    top=3\n",
        "                    scc=[]\n",
        "                    for zz in range(1,top+1):\n",
        "                        ac=topps(zz)\n",
        "                        scc.append(ac)\n",
        "                    return scc,per_txt_nonori_score_avg,per_txt_ori_score_avg,correct_txt_true_pred\n",
        "                    \n",
        "\n",
        "rand_acc={}\n",
        "rand_pscr_nonlb={}\n",
        "rand_pscr_orlb={}\n",
        "correct_txt_true_p={}\n",
        "for vv in range(0,10):\n",
        "    scc,per_txt_nonori_score_avg,per_txt_ori_score_avg,correct_txt_true_pred=tagcls_only()\n",
        "    rand_acc[vv]=scc\n",
        "    rand_pscr_nonlb[vv]=per_txt_nonori_score_avg\n",
        "    rand_pscr_orlb[vv]=per_txt_ori_score_avg\n",
        "    correct_txt_true_p[vv]=correct_txt_true_pred\n",
        "    print(\"\\n\\n\")\n",
        "# Drawing accuracy for the random 100 texts selction\n",
        "\n",
        "# \n",
        "\n",
        "\n",
        "\n",
        "# Score rand_acc\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "vr_t1=[]\n",
        "vr_t2=[]\n",
        "vr_t3=[]\n",
        "for kk in rand_acc:\n",
        "    vr_t1.append(rand_acc[kk][0])\n",
        "    vr_t2.append(rand_acc[kk][1])\n",
        "    vr_t3.append(rand_acc[kk][2])\n",
        "print(vr_t1)\n",
        "print(vr_t2)\n",
        "print(vr_t3)\n",
        "\n",
        "'''\n",
        "nri=[]\n",
        "ori=[]\n",
        "for jj in per_txt_ori_score_avg:\n",
        "     #print(per_txt_ori_ori_rank_avg[jj],per_txt_ori_pred_rank_avg[jj])\n",
        "     nri.append(per_txt_nonori_score_avg[jj])\n",
        "     ori.append(per_txt_ori_score_avg[jj])\n",
        "'''\n",
        "\n",
        "\n",
        "#Geb_b30 = nri#[11, 10, 12, 14, 16, 19, 17, 14, 18, 17]\n",
        "#years_b30 = range(0,len(nri))\n",
        "#Geb_a30 = ori#[12, 10, 13, 14, 12, 13, 18, 16,0,0]\n",
        "#years_a30 = range(0,len(ori))\n",
        "print(len(vr_t1))\n",
        "years_a31 = range(0,len(vr_t1))\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(years_a31, vr_t1, label='Top-1', color='blue')\n",
        "ax.plot(years_a31,vr_t2, label='Top-2', color = 'red')\n",
        "ax.plot(years_a31,vr_t3, label='Top-3', color = 'green')\n",
        "legend = ax.legend(loc='lower right', fontsize='x-large')\n",
        "plt.xlabel('Number of times randomly selected 100 texts')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Variation of Top-K (K=1,2,3) accuracy scores')\n",
        "plt.show()\n",
        "plt.savefig(\"Variation_cluster_10.pdf\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Drawing graphs for the average scores of the original and non-original class labels for raandom 100 text selection\n",
        "\n",
        "\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def draw(kk):\n",
        "            vr_t1=[]\n",
        "            vr_t2=[]\n",
        "            #vr_t3=[]\n",
        "            #rand_pscr_nonlb={}\n",
        "            #rand_pscr_orlb={}\n",
        "            for vv in rand_pscr_nonlb[kk]:\n",
        "                vr_t1.append(rand_pscr_nonlb[kk][vv])\n",
        "                vr_t2.append(rand_pscr_orlb[kk][vv])\n",
        "            print(vr_t1)\n",
        "            print(vr_t2)\n",
        "            #print(vr_t3)\n",
        "\n",
        "            '''\n",
        "            nri=[]\n",
        "            ori=[]\n",
        "            for jj in per_txt_ori_score_avg:\n",
        "                #print(per_txt_ori_ori_rank_avg[jj],per_txt_ori_pred_rank_avg[jj])\n",
        "                nri.append(per_txt_nonori_score_avg[jj])\n",
        "                ori.append(per_txt_ori_score_avg[jj])\n",
        "            '''\n",
        "\n",
        "\n",
        "            #Geb_b30 = nri#[11, 10, 12, 14, 16, 19, 17, 14, 18, 17]\n",
        "            #years_b30 = range(0,len(nri))\n",
        "            #Geb_a30 = ori#[12, 10, 13, 14, 12, 13, 18, 16,0,0]\n",
        "            #years_a30 = range(0,len(ori))\n",
        "            years_a30 = range(0,len(vr_t1))\n",
        "\n",
        "            fig, ax = plt.subplots()\n",
        "            ax.plot(years_a30, vr_t1, label='Non-Original', color='blue')\n",
        "            ax.plot(years_a30,vr_t2, label='Original', color = 'red')\n",
        "            #ax.plot(years_a30,vr_t3, label='Top-3', color = 'green')\n",
        "            legend = ax.legend(loc='upper left', fontsize='x-large')\n",
        "            plt.xlabel(' randomly selected 100 texts')\n",
        "            plt.ylabel('Average_Score')\n",
        "            plt.title('Comparison of Original Label and Non-Oroginal labels Regarding Accuracy')\n",
        "            plt.show()\n",
        "            plt.savefig(\"Accuracy_cluster_5_\"+str(kk)+\".pdf\")\n",
        "for kk in rand_acc:\n",
        "     draw(kk)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3aiCtHXFcSAX"
      },
      "source": [
        "# Randomly selecting the texts by varying the number of the number of texts from 25 to 125 to observe how zero-shot performs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "db3sl5OnclI-"
      },
      "outputs": [],
      "source": [
        "#\n",
        "#RANDOM SELECTION of the texts by varying the number of texts\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy.ma.core import mean\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "import sys\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import numpy as np\n",
        "import operator\n",
        "from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
        "import sys\n",
        "from scipy import spatial\n",
        "from sklearn_extra.cluster import KMedoids\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
        "\n",
        "import math\n",
        "import sys\n",
        "import random\n",
        "import operator\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import numpy as np\n",
        "from scipy import spatial\n",
        "\n",
        "def tagcls_only(bb22):  \n",
        "                    rttext_tagh={}\n",
        "                    mptxt={}\n",
        "                    rttag={}\n",
        "                    allid=[]\n",
        "                    truhh=[]\n",
        "                    bv=100\n",
        "                    vbb=[]\n",
        "                    for kk in rttext_tagh1:\n",
        "                        if txt_rd[str(kk)] not in allid:\n",
        "                            allid.append(txt_rd[str(kk)])\n",
        "\n",
        "                    vz=0\n",
        "                    lm=bb22+100\n",
        "                    for jj in range(0,lm):\n",
        "                        bb1=random.choice(allid)\n",
        "                        if (bb1):\n",
        "                            vz=vz+1\n",
        "                            #if (bb):\n",
        "                            if  len(rttext_tagh)<bb22:\n",
        "                                    rttext_tagh[rd_txt[bb1]]=rttext_tagh1[rd_txt[bb1]]\n",
        "\n",
        "             \n",
        "                    for tt in rttext_tagh:\n",
        "                        for kkk in rttext_tagh[tt]:\n",
        "                            if kkk not in  vbb:\n",
        "                                vbb.append(kkk)\n",
        "\n",
        "                    ss=set(vbb)\n",
        "                    #truhh=[]\n",
        "                    #rttext_tagh={}\n",
        "\n",
        "                    for vv in ss:\n",
        "                        truhh.append( vv)\n",
        "\n",
        "                    print(len(rttext_tagh),len(truhh))\n",
        "                    \n",
        "                    #Accuracy Computation\n",
        "\n",
        "                    #multi tag\n",
        "\n",
        "                    from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "                    import numpy as np\n",
        "                    import operator\n",
        "                    import matplotlib.pyplot as plt\n",
        "                    from transformers import pipeline\n",
        "                    from pylab import rcParams\n",
        "                    import sys \n",
        "                    import nltk\n",
        "                    import re\n",
        "                    import operator\n",
        "                    #from transformers_interpret import ZeroShotClassificationExplainer\n",
        "                    zero_shot_classifier = pipeline(\"zero-shot-classification\")#,model='facebook/bart-large-mnli')#,model='roberta-large-mnli')#model='facebook/bart-large-mnli')#,model='Recognai/zeroshot_selectra_medium')#,model='facebook/bart-large-mnli')\n",
        "                    #tokenizer = AutoTokenizer.from_pretrained(\"Recognai/zeroshot_selectra_medium\")#(\"facebook/bart-base-mnli\")#(\"Recognai/zeroshot_selectra_medium\")\n",
        "                    #model = AutoModelForSequenceClassification.from_pretrained(\"Recognai/zeroshot_selectra_medium\")#(\"facebook/bart-base-mnli\")#(\"Recognai/zeroshot_selectra_medium\")\n",
        "                    #zero_shot_explainer = ZeroShotClassificationExplainer(model, tokenizer)\n",
        "                    # creating embedding of the relational texts\n",
        "                    from sentence_transformers import SentenceTransformer\n",
        "                    from sklearn.cluster import KMeans\n",
        "                    import sys\n",
        "                    from sentence_transformers import SentenceTransformer\n",
        "                    from sklearn.cluster import AgglomerativeClustering\n",
        "                    import numpy as np\n",
        "                    from sentence_transformers import SentenceTransformer\n",
        "                    from sklearn.cluster import KMeans\n",
        "                    from sentence_transformers import SentenceTransformer\n",
        "                    from sklearn.cluster import AgglomerativeClustering\n",
        "                    import numpy as np\n",
        "                    import operator\n",
        "                    from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
        "                    import sys\n",
        "                    from scipy import spatial\n",
        "                    from sklearn_extra.cluster import KMedoids\n",
        "                    import numpy as np\n",
        "                    from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "                    from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
        "\n",
        "                    cn=0\n",
        "                    txt_lbp={}\n",
        "                    ocl_di={}\n",
        "                    pred_l={}\n",
        "                    ocl_dia={}\n",
        "                    pred_lnk={}\n",
        "                    ocl_dnk={}\n",
        "                    pred_tk={}\n",
        "                    ocl_tk={}\n",
        "                    all_txt_label_score={}\n",
        "                    all_txt_label_rank={}\n",
        "                    def get_relational_embedding(s):\n",
        "                            corpus=[]\n",
        "                            s1=''\n",
        "                            for kk in samelocation:\n",
        "                                cc=0\n",
        "                                #for kj in samelocation[kk]:\n",
        "                                if s in samelocation[kk]: \n",
        "                                    for kj in samelocation[kk]:\n",
        "                                        corpus.append(kj)\n",
        "                                        s1=s1+kj+\" \"\n",
        "                                    # cc=cc+1\n",
        "                            embedder = SentenceTransformer('all-MiniLM-L12-v2')\n",
        "                            corpus_embeddings = embedder.encode(corpus)\n",
        "                            return corpus_embeddings,corpus,s1\n",
        "\n",
        "                    # Zero-shot Classification\n",
        "                    def review_explain(text):\n",
        "                           # corpus_embeddings,corpus,s1=get_relational_embedding(text)\n",
        "                            #zero_shot_classifier = pipeline(\"zero-shot-classification\")#.preprocess(corpus)#.transform(corpus)#.save_pretrained(corpus_embeddings)#,corpus_embeddings)\n",
        "                        \n",
        "                            result = zero_shot_classifier(sequences =text,candidate_labels =truhh,multi_label=True)\n",
        "                            #zero_shot_classifier(sequences =t,candidate_labels =truhh,multi_label=False)\n",
        "                            return result['labels'],result['scores']\n",
        "\n",
        "                    \n",
        "                    for tt in rttext_tagh:\n",
        "                       # import sys\n",
        "                        #print(len(rttext_tagh[tt]))\n",
        "                        #sys.exit()\n",
        "                        mpd={}\n",
        "                        nlb=[]\n",
        "                        mpd_nk={}\n",
        "                        mpd_tk={}\n",
        "                        nlb_tk=[]\n",
        "                        nlb_nk=[]\n",
        "                        rn={}\n",
        "                        rsc={}\n",
        "                        clas,score= review_explain(tt)\n",
        "                    \n",
        "                        for bb in range(0,len(clas)):\n",
        "                            rsc[clas[bb]]=score[bb]\n",
        "                        for bb in range(0,len(clas)):\n",
        "                            rn[clas[bb]]=bb+1\n",
        "                        all_txt_label_score[tt]=rsc\n",
        "                        all_txt_label_rank[tt]=rn\n",
        "                        for k1 in rttext_tagh[tt]:\n",
        "                                for t3 in range(0,len(clas)):\n",
        "                                    if str(clas[t3])==str(k1):\n",
        "                                        mpd[k1]=score[t3]\n",
        "                        for k1 in rttext_tagh[tt]:\n",
        "                                for t3 in range(0,len(clas)):\n",
        "                                    if str(clas[t3])!=str(k1):\n",
        "                                        if score[t3]>0.5:\n",
        "                                            mpd_nk[k1]=score[t3]\n",
        "                        for k1 in rttext_tagh[tt]:\n",
        "                                for t3 in range(0,len(clas)):\n",
        "                                    if str(clas[t3])==str(k1):\n",
        "                                        if score[t3]>0.5:\n",
        "                                            mpd_tk[k1]=score[t3]\n",
        "                        \n",
        "                        dd=sorted(mpd.items(), key=operator.itemgetter(1),reverse=True)\n",
        "                        dd1=sorted(mpd_nk.items(), key=operator.itemgetter(1),reverse=True)\n",
        "                        dd2=sorted(mpd_tk.items(), key=operator.itemgetter(1),reverse=True)\n",
        "                        \n",
        "                        for zz in dd:\n",
        "                            nlb.append(zz[0])\n",
        "                        for zz1 in dd1:\n",
        "                            nlb_nk.append(zz1[0])\n",
        "                        for zz2 in dd2:\n",
        "                            nlb_tk.append(zz2[0])\n",
        "                        \n",
        "                        pred_lnk[tt]=nlb_nk #ranked list of the non-original labels has pribability greater than 50%\n",
        "                        pred_tk[tt]=nlb_tk#ranked list of the original labels has pribability greater than and equal 90% and appear in top N labels\n",
        "                        ocl_di[tt]=nlb[0:1]#single label with the highest score of the original label\n",
        "                        ocl_dia[tt]=nlb#ranked list of the original label\n",
        "                        \n",
        "\n",
        "                        txt_lbp[tt]=clas[0:10]\n",
        "                        pred_l[tt]=clas\n",
        "                    \n",
        "\n",
        "                    '''\n",
        "                    Comparing average rank of the predicted original labels with that of it ideal rank positon\n",
        "                    Coounting the number of non-original labels that have higher probability scores than that of original labels per text\n",
        "\n",
        "                    '''\n",
        "                    # average rank\n",
        "                    ccc=0\n",
        "                    KK=3 # number of top predicted non-original labels\n",
        "\n",
        "                    per_txt_ori_rank_cmp={}\n",
        "                    per_txt_ori_score_avg={}\n",
        "                    per_txt_nonori_rank_cmp={}\n",
        "                    per_txt_nonori_pred_rank_avg={}\n",
        "                    per_txt_nonori_ori_rank_avg={}\n",
        "                    per_txt_nonori_score_avg={}\n",
        "                    per_txt_ori_pred_rank_avg={}\n",
        "                    per_txt_ori_ori_rank_avg={}\n",
        "                    per_txt_nonori_top_n={}\n",
        "\n",
        "                    #import sys\n",
        "                    #print(len(all_txt_label_score))\n",
        "                   # sys.exit()\n",
        "                    for v in all_txt_label_score:\n",
        "                      if v in rttext_tagh:\n",
        "                        #import sys\n",
        "                        #print(len(rttext_tagh[v]))\n",
        "                        #sys.exit()\n",
        "                        orn=(len(rttext_tagh[v])+1)/2 # Ideal average rank position\n",
        "                        s=0\n",
        "                        sc=0\n",
        "                        cz=0\n",
        "                        nr=[]\n",
        "                        sno=0\n",
        "                        snosc=0\n",
        "                        for kz in all_txt_label_rank[v]:\n",
        "                            if kz not in rttext_tagh[v]:\n",
        "                                if cz<KK:\n",
        "                                        if kz not in nr:\n",
        "                                                nr.append(kz)\n",
        "                                                #print(kz,rttext_tagu[v],all_txt_label_rank[v][kz],all_txt_label_score[v][kz])\n",
        "                                                sno=sno+float(all_txt_label_rank[v][kz])\n",
        "                                                snosc=snosc+float(all_txt_label_score[v][kz])\n",
        "                                                cz=cz+1\n",
        "                        #print(\"\\n\")\n",
        "                        per_txt_nonori_top_n[v]=nr\n",
        "                        per_txt_nonori_rank_cmp[v]=sno/KK\n",
        "                        per_txt_nonori_score_avg[v]=snosc/KK\n",
        "\n",
        "                        for kz in all_txt_label_rank[v]:\n",
        "                            if kz in rttext_tagh[v]:\n",
        "                                s=s+float(all_txt_label_rank[v][kz])\n",
        "                                sc=sc+float(all_txt_label_score[v][kz])\n",
        "                        #import sys\n",
        "                        #print(len(rttext_tagh[v]))\n",
        "                        #sys.exit()\n",
        "                       # try:\n",
        "                        prn=s/len(rttext_tagh[v])\n",
        "                        per_txt_ori_score_avg[v]=sc/len(rttext_tagh[v])\n",
        "                        per_txt_ori_pred_rank_avg[v]=prn\n",
        "                        per_txt_ori_ori_rank_avg[v]=orn\n",
        "                        # print(prn)\n",
        "                        dif=abs(prn-orn)\n",
        "                        per_txt_ori_rank_cmp[v]=dif\n",
        "                        #except:\n",
        "                            #continue\n",
        "                        if dif<=0.0:\n",
        "                            ccc=ccc+1\n",
        "                    print(\"Number of texts where the position of the original labels preserved after prediction\")\n",
        "                    print(ccc)\n",
        "                    print(\"Percentage of texts where the position of the original labels preserved after prediction\")\n",
        "                    print(ccc/len(txt_lbp))\n",
        "\n",
        "\n",
        "                    # average scores\n",
        "\n",
        "                    vvv=0\n",
        "                    for jj in per_txt_ori_score_avg:\n",
        "                        if per_txt_nonori_score_avg[jj]>per_txt_ori_score_avg[jj]:\n",
        "                                    vvv=vvv+1\n",
        "\n",
        "                    print(\"Number of non-original labels have higher prediction acores than original labels after prediction\")\n",
        "                                \n",
        "                    print(vvv)\n",
        "\n",
        "                    '''\n",
        "                    Accuracy for the clustered labels\n",
        "                    '''\n",
        "                    #accuracy of multi-level classification with k-means clustering\n",
        "                    correct_txt_true_pred=[]\n",
        "                    def topps(n):\n",
        "                                cc=0\n",
        "                                vb1=0\n",
        "                                for tt in txt_lbp:\n",
        "                                        #if vb1 < 1000:\n",
        "                                                #vb1=vb1+1 \n",
        "                                                try:\n",
        "                                                    for vb in txt_lbp[tt][0:n]:\n",
        "                                                            #print(rttext_tagh[tt][0],vb)\n",
        "                                                            if vb in rttext_tagh[tt][0:n]:\n",
        "                                                            #if str(vb) ==str(rttext_tagh[tt][0]):\n",
        "                                                                cc=cc+1\n",
        "                                                                if tt not in correct_txt_true_pred:\n",
        "                                                                            correct_txt_true_pred.append(tt)\n",
        "                                                                break\n",
        "                                                            else:\n",
        "                                                                continue\n",
        "\n",
        "                                                except:\n",
        "                                                    continue\n",
        "                                                \n",
        "                                #txt_lbp\n",
        "                                print(\"Top_\"+str(n)+ \" Prediction Score: \")\n",
        "                                print(cc/len(txt_lbp))\n",
        "                                ac=cc/len(txt_lbp)\n",
        "                                return ac\n",
        "                    top=3\n",
        "                    scc=[]\n",
        "                    for zz in range(1,top+1):\n",
        "                        ac=topps(zz)\n",
        "                        scc.append(ac)\n",
        "                    return scc,per_txt_nonori_score_avg,per_txt_ori_score_avg,correct_txt_true_pred,per_txt_ori_pred_rank_avg,per_txt_ori_ori_rank_avg\n",
        "                    \n",
        "\n",
        "rand_acc={}\n",
        "rand_pscr_nonlb={}\n",
        "rand_pscr_orlb={}\n",
        "rand_predi_rank_orlb={}\n",
        "rand_ori_rank_orlb={}\n",
        "correct_txt_true_p={}\n",
        "count_percl_hosctxt={}\n",
        "count_percl_txt={}\n",
        "def rand_size(bb):\n",
        "    for vv in range(0,5):\n",
        "        scc,per_txt_nonori_score_avg,per_txt_ori_score_avg,correct_txt_true_pred,per_txt_ori_pred_rank_avg,per_txt_ori_ori_rank_avg=tagcls_only(bb)\n",
        "        rand_acc[vv]=scc\n",
        "        rand_pscr_nonlb[vv]=per_txt_nonori_score_avg\n",
        "        rand_pscr_orlb[vv]=per_txt_ori_score_avg\n",
        "        correct_txt_true_p[vv]=correct_txt_true_pred\n",
        "        rand_predi_rank_orlb[vv]=per_txt_ori_pred_rank_avg\n",
        "        rand_ori_rank_orlb[vv]=per_txt_ori_ori_rank_avg\n",
        "        #count_percl_hosctxt[vv]=nmmm\n",
        "        #count_percl_txt[vv]=len(final_clut2[tt11])\n",
        "        print(\"\\n\\n\")\n",
        "    return rand_acc,rand_pscr_nonlb,rand_pscr_orlb,rand_predi_rank_orlb,rand_ori_rank_orlb,count_percl_hosctxt,count_percl_txt\n",
        "\n",
        "\n",
        "\n",
        "s1=[]\n",
        "b1=[]\n",
        "sb1=[]\n",
        "noc1=[]\n",
        "oc1=[]\n",
        "clsize=[]\n",
        "\n",
        "for bn in range(25,126,25):\n",
        "      print(\"Random \"+ str(bn))\n",
        "      rand_acc,rand_pscr_nonlb,rand_pscr_orlb,rand_predi_rank_orlb,rand_ori_rank_orlb,count_percl_hosctxt,count_percl_txt=rand_size(bn)\n",
        "      vr_t1=[]\n",
        "      vr_t2=[]\n",
        "      vr_t3=[]\n",
        "      for kk in rand_acc:\n",
        "            vr_t1.append(rand_acc[kk][0])\n",
        "            vr_t2.append(rand_acc[kk][1])\n",
        "            vr_t3.append(rand_acc[kk][2])\n",
        "      non=[]\n",
        "      for vv in rand_pscr_nonlb:\n",
        "          s11=0\n",
        "          for kk in rand_pscr_nonlb[vv]:\n",
        "              #s1=0\n",
        "              #for tx in rand_pscr_nonlb[vv][kk]:\n",
        "              s11=s11+rand_pscr_nonlb[vv][kk]\n",
        "          sv=s11/len(rand_pscr_nonlb[vv])\n",
        "          non.append(sv)\n",
        "      sv1=mean(non)\n",
        "      noc1.append(sv1)\n",
        "      on=[]\n",
        "      for vv in rand_pscr_orlb:\n",
        "          s5=0\n",
        "          for kk in rand_pscr_orlb[vv]:\n",
        "              #s11=0\n",
        "              #for tx in rand_pscr_orlb[vv][kk]:\n",
        "                  s5=s5+rand_pscr_orlb[vv][kk]\n",
        "          sv2=s5/len(rand_pscr_orlb[vv])\n",
        "          on.append(sv2)\n",
        "      sv3=mean(on)\n",
        "      oc1.append(sv3)\n",
        "\n",
        "\n",
        "      vb1=mean(vr_t1)\n",
        "      s1.append(vb1)\n",
        "      vb2=mean(vr_t2)\n",
        "      b1.append(vb2)\n",
        "      vb3=mean(vr_t3)\n",
        "      sb1.append(vb3)\n",
        "      print(s1,b1,sb1)\n",
        "     # clsize.append(len(final_clut2))\n",
        "        \n",
        "\n",
        "# Drawing Varying the number of texts randomly\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "Accuracy\n",
        "'''\n",
        "\n",
        "\n",
        "#Geb_b30 = nri#[11, 10, 12, 14, 16, 19, 17, 14, 18, 17]\n",
        "#years_b30 = range(0,len(nri))\n",
        "#Geb_a30 = ori#[12, 10, 13, 14, 12, 13, 18, 16,0,0]\n",
        "#years_a30 = range(0,len(ori))\n",
        "#print(len(vr_t1))\n",
        "#Drawing the average acuuracy with the increament of the text size\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.dates import date2num\n",
        "import sys\n",
        "import pylab \n",
        "\n",
        "#s1=[0.2, 0.296, 0.21600000000000003, 0.21600000000000003, 0.2624]\n",
        "#b1=[0.728, 0.78, 0.7066666666666667, 0.7300000000000001, 0.6704000000000001]\n",
        "#sb1=[0.8640000000000001, 0.844, 0.7706666666666666, 0.804, 0.7647999999999999]\n",
        "years_a31 = range(25,126,25)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(years_a31, s1, label='Top-1', color='blue')\n",
        "ax.plot(years_a31,b1, label='Top-2', color = 'red')\n",
        "ax.plot(years_a31,sb1, label='Top-3', color = 'green')\n",
        "legend = ax.legend(loc='lower right', fontsize='x-large')\n",
        "plt.xlabel('Randomly Choosing the Text Data')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(' Top-K (K=1,2,3) accuracy scores')\n",
        "plt.show()\n",
        "plt.savefig(\"vt_txt_size_acc_zero.pdf\")\n",
        "pylab.show()\n",
        "\n",
        "# Average score of non-original and original  varying cluster  (Random)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.dates import date2num\n",
        "import sys\n",
        "import pylab \n",
        "\n",
        "years_a31 = range(25,126,25)\n",
        "#noc1=[0.8057282710870106, 0.8258386753797531, 0.8569131283760072, 0.8452732372283933, 0.8594713402748109]\n",
        "#oc1=[0.7554763378689533, 0.7521192745907562, 0.7499143993404642, 0.7511222235150612, 0.7439288047549906]\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(years_a31,noc1, label='Non-Oroginal Class', color='blue')\n",
        "ax.plot(years_a31,oc1, label='Original Class', color = 'red')\n",
        "#ax.plot(years_a31,vr_t3, label='Top-3', color = 'green')\n",
        "legend = ax.legend(loc='lower right', fontsize='x-large')\n",
        "plt.xlabel('Randomly Choosing the Text Data')\n",
        "plt.ylabel('Average Probability Score')\n",
        "plt.title(' Comparison of Original Class and Non-Original Class Concerning Average Probability Score')\n",
        "plt.show()\n",
        "plt.savefig(\"vt_txt_size_avg_score_zero.pdf\")\n",
        "pylab.show()\n",
        "\n",
        "'''\n",
        "#Drawing the average acuuracy with the increament of the text size\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.dates import date2num\n",
        "import sys\n",
        "import pylab \n",
        "\n",
        "s1=[0.2, 0.296, 0.21600000000000003, 0.21600000000000003, 0.2624]\n",
        "b1=[0.728, 0.78, 0.7066666666666667, 0.7300000000000001, 0.6704000000000001]\n",
        "sb1=[0.8640000000000001, 0.844, 0.7706666666666666, 0.804, 0.7647999999999999]\n",
        "years_a31 = range(25,126,25)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(years_a31, s1, label='Top-1', color='blue')\n",
        "ax.plot(years_a31,b1, label='Top-2', color = 'red')\n",
        "ax.plot(years_a31,sb1, label='Top-3', color = 'green')\n",
        "legend = ax.legend(loc='lower right', fontsize='x-large')\n",
        "plt.xlabel('Randomly Choosing the Text Data')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(' Top-K (K=1,2,3) accuracy scores')\n",
        "plt.show()\n",
        "plt.savefig(\"vt_txt_size_acc_zero.pdf\")\n",
        "pylab.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "'''\n",
        "# Average score of non-original and original  varying the number of texts  (Random)\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.dates import date2num\n",
        "import sys\n",
        "import pylab \n",
        "\n",
        "years_a31 = range(25,126,25)\n",
        "noc1=[0.8057282710870106, 0.8258386753797531, 0.8569131283760072, 0.8452732372283933, 0.8594713402748109]\n",
        "oc1=[0.7554763378689533, 0.7521192745907562, 0.7499143993404642, 0.7511222235150612, 0.7439288047549906]\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(years_a31,noc1, label='Non-Oroginal Class', color='blue')\n",
        "ax.plot(years_a31,oc1, label='Original Class', color = 'red')\n",
        "#ax.plot(years_a31,vr_t3, label='Top-3', color = 'green')\n",
        "legend = ax.legend(loc='lower right', fontsize='x-large')\n",
        "plt.xlabel('Randomly Choosing the Text Data')\n",
        "plt.ylabel('Average Probability Score')\n",
        "plt.title(' Comparison of Original Class and Non-Original Class Concerning Average Probability Score')\n",
        "plt.show()\n",
        "plt.savefig(\"vt_txt_size_avg_score_zero.pdf\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PKIAyLVcclgY"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ZGbp8-JVniW"
      },
      "source": [
        "# Here we observe the performance of the zero-shot for the cluster based approach. In this regard, here we kept the the number of cluster of the texts fixed and we vary the number of cluster of the classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IYceNgksrTAs"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gl9FsuyJrTJ1"
      },
      "outputs": [],
      "source": [
        "#Tag Clustering using Agglomerative and K-medoids Clustering  (Clustering classes)\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy.ma.core import mean\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "import sys\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import numpy as np\n",
        "import operator\n",
        "from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
        "import sys\n",
        "from scipy import spatial\n",
        "from sklearn_extra.cluster import KMedoids\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
        "\n",
        "import math\n",
        "import sys\n",
        "import random\n",
        "import operator\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import numpy as np\n",
        "from scipy import spatial\n",
        "import random   \n",
        "\n",
        "\n",
        "def labe_cl(n):\n",
        "            #Unique Tag list\n",
        "            embedder = SentenceTransformer('all-MiniLM-L12-v2')\n",
        "            tagu=[]\n",
        "            tagu1=[]\n",
        "            stt=[]\n",
        "            sent=[]\n",
        "            relation_sent=[]\n",
        "            for  sz in rttext_tag2:\n",
        "                    s=''\n",
        "                    gh=[]\n",
        "                    for vb in rttext_tag2[sz]:\n",
        "                        #if vb not in stt:\n",
        "                            # s=str(vb)+\" \"+sz\n",
        "                            #if vb not in tagu1:\n",
        "                                #gh.append(vb)\n",
        "                                #tagu1.append(vb)\n",
        "                            #gh.append(sz)\n",
        "                            s=s+str(vb)+\" \"+str(sz)+\" \"\n",
        "                            relation_sent.append(s)\n",
        "                            if vb not in gh:\n",
        "                                    gh.append(vb)\n",
        "                            if vb not in stt:\n",
        "                                    stt.append(vb)\n",
        "                            vb1=sz.split()\n",
        "                            for zx in vb1:\n",
        "                                    if zx not in gh:\n",
        "                                        gh.append(zx)\n",
        "                            sent.append(gh)\n",
        "                            \n",
        "            ds=set(stt)\n",
        "            for kk in ds:\n",
        "                tagu.append(kk)\n",
        "           # print(len(tagu))\n",
        "            for tt in tagu:\n",
        "                pass\n",
        "\n",
        "            corpus =tagu#tagss# tagu\n",
        "            crp_txt={}\n",
        "            corpus_embeddings = embedder.encode(corpus)\n",
        "            for sentence, embedding in zip(tagu, corpus_embeddings):\n",
        "                lst=embedding.tolist()\n",
        "                crp_txt[sentence]=lst\n",
        "            vectorizer = TfidfVectorizer()\n",
        "            X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "            num_clusters=n #{random, heuristic, k-medoids++, build\n",
        "            kmedoids = KMedoids(n_clusters=num_clusters,metric='cosine', method='alternate',init='k-medoids++', max_iter=500000, random_state=1).fit(X)\n",
        "            cluster_assignment,cn=kmedoids.labels_,kmedoids.cluster_centers_\n",
        "\n",
        "            clustered_sentences = {}\n",
        "            clustered_sentences1 = {}\n",
        "            for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
        "                if cluster_id not in clustered_sentences:\n",
        "                    clustered_sentences[cluster_id] = []\n",
        "                    clustered_sentences1[cluster_id] = []\n",
        "                if corpus[sentence_id] in tagu:\n",
        "                        clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
        "                if len(vectorizer.inverse_transform(cn[cluster_id])[0])==2:\n",
        "                    gh=str(vectorizer.inverse_transform(cn[cluster_id])[0][0])+\"-\"+str(vectorizer.inverse_transform(cn[cluster_id])[0][1])\n",
        "                \n",
        "                    if gh not in clustered_sentences1[cluster_id]:\n",
        "                        clustered_sentences1[cluster_id].append(gh)\n",
        "                    \n",
        "                if len(vectorizer.inverse_transform(cn[cluster_id])[0])==1:\n",
        "                    for vv in vectorizer.inverse_transform(cn[cluster_id])[0]:\n",
        "                        if vv not in clustered_sentences1[cluster_id]:\n",
        "                                clustered_sentences1[cluster_id].append(vv)\n",
        "                    \n",
        "            final_clut1=clustered_sentences\n",
        "\n",
        "\n",
        "            final_cluh={}\n",
        "            for kk in final_clut1:\n",
        "                    final_cluh[kk]=clustered_sentences1[kk]\n",
        "            '''\n",
        "            final_cluh={}\n",
        "            for kk in final_clut1:\n",
        "                gh=[]\n",
        "                if len(final_clut1[kk])%2==0:\n",
        "                        pp=len(final_clut1[kk])//2\n",
        "                        #gh.append(final_clut1[kk][pp-1])\n",
        "                        gh.append(final_clut1[kk][pp])\n",
        "                        final_cluh[kk]=gh         \n",
        "                elif len(final_clut1[kk])%2!=0:\n",
        "                        pp=len(final_clut1[kk])//2\n",
        "                        gh.append(final_clut1[kk][pp])\n",
        "                        final_cluh[kk]=gh\n",
        "\n",
        "            '''\n",
        "            for t in final_clut1:\n",
        "               pass# print(final_cluh[t])\n",
        "            #Re-assigning the labels \n",
        "\n",
        "            embedder = SentenceTransformer('all-MiniLM-L12-v2')\n",
        "\n",
        "\n",
        "            #final_cluh={}\n",
        "            rttext_tagh1={}\n",
        "            rttext_tagh={}\n",
        "            cc=0\n",
        "            mptxt={}\n",
        "            rttag={}\n",
        "            allid=[]\n",
        "            truhh=[]\n",
        "            vbb=[]\n",
        "\n",
        "            from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
        "            import numpy as np\n",
        "            for kk in final_clut1:\n",
        "                for vz in rttext_tag2:\n",
        "                    ggh=[]\n",
        "                    ggh0=[]\n",
        "                    ggh1=[]\n",
        "                    ggh11=[]\n",
        "                    ggh111=[]\n",
        "                    c=0\n",
        "                    #corpus_embeddings = embedder.encode(vz)\n",
        "                    for zx in rttext_tag2[vz]:\n",
        "                        if zx in final_clut1[kk]:\n",
        "                            for vb3 in final_cluh[kk]:\n",
        "                                #if vb3 in sametopic_rl:\n",
        "                                    #if vz in sametopic_rl[vb3]:\n",
        "                                            if vb3 not in ggh:\n",
        "                                                ggh.append(vb3)\n",
        "                                    #else:\n",
        "                                        #continue\n",
        "                            if len(ggh)>0:\n",
        "                                rttext_tagh1[vz]=ggh\n",
        "                            break\n",
        "                        else:\n",
        "                            continue\n",
        "                    \n",
        "\n",
        "            jj=[]\n",
        "            for vv in rttext_tagh1:\n",
        "                for jk in rttext_tagh1[vv]:\n",
        "                    if jk not in jj:\n",
        "                        jj.append(jk)\n",
        "            #print(len(jj),len(rttext_tagh1))\n",
        "            # Clustering the text with pre-processed labels\n",
        "            snt=[]\n",
        "            rttext_tagh={}\n",
        "\n",
        "\n",
        "            truhh=[]\n",
        "            for jj in rttext_tagh1:\n",
        "                snt.append(jj)\n",
        "\n",
        "\n",
        "\n",
        "            embedder = SentenceTransformer('all-MiniLM-L12-v2')#('all-distilroberta-v1')#('all-MiniLM-L12-v2')#('all-distilroberta-v1')#('all-MiniLM-L12-v2')\n",
        "            # Corpus with example sentences\n",
        "            corpus = snt\n",
        "            corpus_embeddings = embedder.encode(corpus)\n",
        "\n",
        "            #num_clusters = 10\n",
        "\n",
        "            # Normalize the embeddings to unit length\n",
        "            corpus_embeddings = corpus_embeddings /  np.linalg.norm(corpus_embeddings, axis=1, keepdims=True)\n",
        "\n",
        "            # Perform Agglomerative clustering\n",
        "            clustering_model = AgglomerativeClustering(n_clusters=None,distance_threshold=1.50) #, affinity='cosine', linkage='average', distance_threshold=0.4)\n",
        "            clustering_model.fit(corpus_embeddings)\n",
        "            cluster_assignment,dis = clustering_model.labels_,clustering_model.distances_\n",
        "            #print(dis)\n",
        "            clustered_sentences = {}\n",
        "            for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
        "                if cluster_id not in clustered_sentences:\n",
        "                    clustered_sentences[cluster_id] = []\n",
        "\n",
        "                clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
        "            final_clut11={}\n",
        "\n",
        "            for i, cluster in clustered_sentences.items():\n",
        "                cls=[]\n",
        "                vc=0\n",
        "                #f len(cluster)>=10:\n",
        "                for kk in cluster:\n",
        "                 if vc<100:\n",
        "                    if kk not in cls:\n",
        "                        cls.append(kk)\n",
        "                        vc=vc+1\n",
        "                final_clut11[i]=cls\n",
        "                #print(cluster[0])\n",
        "\n",
        "                #print(\"Cluster \", i+1)\n",
        "                #print(cluster)\n",
        "                #print(\"\")\n",
        "            cln=0\n",
        "            final_clut2={}\n",
        "\n",
        "            for tt in final_clut11:  \n",
        "                    if len(final_clut11[tt])>=10:\n",
        "                    \n",
        "                            final_clut2[cln]=final_clut11[tt]\n",
        "                            cln=cln+1\n",
        "                        # vc=vc+1\n",
        "            print(len(final_clut2))\n",
        "            return final_clut2,rttext_tagh1\n",
        "\n",
        "\n",
        "#Clusteredtext with pre-processed labels\n",
        "\n",
        "def lb_txt_cl(final_clut2,rttext_tagh1):\n",
        "            test={}\n",
        "            def tagcls_only_cls():\n",
        "                            rttext_tagh={}     \n",
        "                            truhh=[]  \n",
        "                            #tt=random.randint(0,len(final_clut2)-1)\n",
        "\n",
        "                            for vv in final_clut2[tt11]:\n",
        "                                                if vv not in rttext_tagh:\n",
        "                                                    rttext_tagh[vv]=rttext_tagh1[vv]\n",
        "                            tr=[]\n",
        "                            for tt in rttext_tagh:\n",
        "                                #print(rttext_tagh[tt][0])\n",
        "                                if rttext_tagh[tt][0] not in tr:\n",
        "                                    tr.append(rttext_tagh[tt][0])\n",
        "                            s=set(tr)\n",
        "                            for bb in s:\n",
        "                                truhh.append(bb)\n",
        "                            print(\"Cluster: \"+str(tt11))\n",
        "                            print(len(truhh),len(rttext_tagh))\n",
        "\n",
        "                            #Accuracy Computation\n",
        "\n",
        "                            #multi tag\n",
        "\n",
        "                            from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "                            import numpy as np\n",
        "                            import operator\n",
        "                            import matplotlib.pyplot as plt\n",
        "                            from transformers import pipeline\n",
        "                            from pylab import rcParams\n",
        "                            import sys \n",
        "                            import nltk\n",
        "                            import re\n",
        "                            import operator\n",
        "                            #from transformers_interpret import ZeroShotClassificationExplainer\n",
        "                            zero_shot_classifier = pipeline(\"zero-shot-classification\")#,model='roberta-large-mnli')#model='facebook/bart-large-mnli')#,model='Recognai/zeroshot_selectra_medium')#,model='facebook/bart-large-mnli')\n",
        "                            #tokenizer = AutoTokenizer.from_pretrained(\"Recognai/zeroshot_selectra_medium\")#(\"facebook/bart-base-mnli\")#(\"Recognai/zeroshot_selectra_medium\")\n",
        "                            #model = AutoModelForSequenceClassification.from_pretrained(\"Recognai/zeroshot_selectra_medium\")#(\"facebook/bart-base-mnli\")#(\"Recognai/zeroshot_selectra_medium\")\n",
        "                            #zero_shot_explainer = ZeroShotClassificationExplainer(model, tokenizer)\n",
        "                            cn=0\n",
        "                            txt_lbp={}\n",
        "                            ocl_di={}\n",
        "                            pred_l={}\n",
        "                            ocl_dia={}\n",
        "                            pred_lnk={}\n",
        "                            ocl_dnk={}\n",
        "                            pred_tk={}\n",
        "                            ocl_tk={}\n",
        "                            all_txt_label_score={}\n",
        "                            all_txt_label_rank={}\n",
        "\n",
        "                            # Zero-shot Classification\n",
        "                            def review_explain(text):\n",
        "                                    result = zero_shot_classifier(sequences =text,candidate_labels =truhh ,multi_label=True)\n",
        "                                    \n",
        "                                    return result['labels'],result['scores']\n",
        "\n",
        "                            for tt in rttext_tagh:\n",
        "                                mpd={}\n",
        "                                nlb=[]\n",
        "                                mpd_nk={}\n",
        "                                mpd_tk={}\n",
        "                                nlb_tk=[]\n",
        "                                nlb_nk=[]\n",
        "                                rn={}\n",
        "                                rsc={}\n",
        "                                clas,score= review_explain(tt)\n",
        "                            \n",
        "                                for bb in range(0,len(clas)):\n",
        "                                    rsc[clas[bb]]=score[bb]\n",
        "                                for bb in range(0,len(clas)):\n",
        "                                    rn[clas[bb]]=bb+1\n",
        "                                all_txt_label_score[tt]=rsc\n",
        "                                all_txt_label_rank[tt]=rn\n",
        "                                for k1 in rttext_tagh[tt]:\n",
        "                                        for t3 in range(0,len(clas)):\n",
        "                                            if str(clas[t3])==str(k1):\n",
        "                                                mpd[k1]=score[t3]\n",
        "                                for k1 in rttext_tagh[tt]:\n",
        "                                        for t3 in range(0,len(clas)):\n",
        "                                            if str(clas[t3])!=str(k1):\n",
        "                                                if score[t3]>0.5:\n",
        "                                                    mpd_nk[k1]=score[t3]\n",
        "                                for k1 in rttext_tagh[tt]:\n",
        "                                        for t3 in range(0,len(clas)):\n",
        "                                            if str(clas[t3])==str(k1):\n",
        "                                                if score[t3]>0.5:\n",
        "                                                    mpd_tk[k1]=score[t3]\n",
        "                                \n",
        "                                dd=sorted(mpd.items(), key=operator.itemgetter(1),reverse=True)\n",
        "                                dd1=sorted(mpd_nk.items(), key=operator.itemgetter(1),reverse=True)\n",
        "                                dd2=sorted(mpd_tk.items(), key=operator.itemgetter(1),reverse=True)\n",
        "                                \n",
        "                                for zz in dd:\n",
        "                                    nlb.append(zz[0])\n",
        "                                for zz1 in dd1:\n",
        "                                    nlb_nk.append(zz1[0])\n",
        "                                for zz2 in dd2:\n",
        "                                    nlb_tk.append(zz2[0])\n",
        "                                \n",
        "                                pred_lnk[tt]=nlb_nk #ranked list of the non-original labels has pribability greater than 50%\n",
        "                                pred_tk[tt]=nlb_tk#ranked list of the original labels has pribability greater than and equal 90% and appear in top N labels\n",
        "                                ocl_di[tt]=nlb[0:1]#single label with the highest score of the original label\n",
        "                                ocl_dia[tt]=nlb#ranked list of the original label\n",
        "                                \n",
        "\n",
        "                                txt_lbp[tt]=clas[0:10]\n",
        "                                pred_l[tt]=clas\n",
        "                                #test[tt11]=\n",
        "\n",
        "                            '''\n",
        "                            Comparing average rank of the predicted original labels with that of it ideal rank positon\n",
        "                            Coounting the number of non-original labels that have higher probability scores than that of original labels per text\n",
        "\n",
        "                            '''\n",
        "                            # average rank\n",
        "                            ccc=0\n",
        "                            KK=3 # number of top predicted non-original labels\n",
        "\n",
        "                            per_txt_ori_rank_cmp={}\n",
        "                            per_txt_ori_score_avg={}\n",
        "                            per_txt_nonori_rank_cmp={}\n",
        "                            per_txt_nonori_pred_rank_avg={}\n",
        "                            per_txt_nonori_ori_rank_avg={}\n",
        "                            per_txt_nonori_score_avg={}\n",
        "                            per_txt_ori_pred_rank_avg={}\n",
        "                            per_txt_ori_ori_rank_avg={}\n",
        "                            per_txt_nonori_top_n={}\n",
        "\n",
        "\n",
        "                            for v in all_txt_label_score:\n",
        "                            #if v in rttext_tagh:\n",
        "                                orn=(len(rttext_tagh[v])+1)/2 # Ideal average rank position\n",
        "                                s=0\n",
        "                                sc=0\n",
        "                                cz=0\n",
        "                                nr=[]\n",
        "                                sno=0\n",
        "                                snosc=0\n",
        "                                for kz in all_txt_label_rank[v]:\n",
        "                                    if kz not in rttext_tagh[v]:\n",
        "                                        if cz<KK:\n",
        "                                                if kz not in nr:\n",
        "                                                        nr.append(kz)\n",
        "                                                        #print(kz,rttext_tagu[v],all_txt_label_rank[v][kz],all_txt_label_score[v][kz])\n",
        "                                                        sno=sno+float(all_txt_label_rank[v][kz])\n",
        "                                                        snosc=snosc+float(all_txt_label_score[v][kz])\n",
        "                                                        cz=cz+1\n",
        "                                #print(\"\\n\")\n",
        "                                per_txt_nonori_top_n[v]=nr\n",
        "                                per_txt_nonori_rank_cmp[v]=sno/KK\n",
        "                                per_txt_nonori_score_avg[v]=snosc/KK\n",
        "\n",
        "                                for kz in all_txt_label_rank[v]:\n",
        "                                    if kz in rttext_tagh[v]:\n",
        "                                        s=s+float(all_txt_label_rank[v][kz])\n",
        "                                        sc=sc+float(all_txt_label_score[v][kz])\n",
        "                            \n",
        "                                prn=s/len(rttext_tagh[v])\n",
        "                                per_txt_ori_score_avg[v]=sc/len(rttext_tagh[v])\n",
        "                                per_txt_ori_pred_rank_avg[v]=prn\n",
        "                                per_txt_ori_ori_rank_avg[v]=orn\n",
        "                                #print(prn,orn)\n",
        "                                dif=abs(prn-orn)\n",
        "                                per_txt_ori_rank_cmp[v]=dif\n",
        "                                if dif<=0.0:\n",
        "                                    ccc=ccc+1\n",
        "                            print(\"Number of texts where the position of the original labels preserved after prediction\")\n",
        "                            print(ccc,len(txt_lbp))\n",
        "                            print(\"Percentage of texts where the position of the original labels preserved after prediction\")\n",
        "                            print(ccc/len(txt_lbp))\n",
        "\n",
        "\n",
        "                            # average scores\n",
        "\n",
        "                            vvv=0\n",
        "                            for jj in per_txt_ori_score_avg:\n",
        "                                if per_txt_nonori_score_avg[jj]>per_txt_ori_score_avg[jj]:\n",
        "                                            vvv=vvv+1\n",
        "\n",
        "                            print(\"Number of non-original labels have higher prediction acores than original labels after prediction\")\n",
        "                            nmmm=vvv     \n",
        "                            print(vvv)\n",
        "                            #if tt11==1:\n",
        "                            # for kk in txt_lbp:\n",
        "                                #  pass#print(kk,txt_lbp[kk],rttext_tagh[kk])\n",
        "\n",
        "                            '''\n",
        "                            Accuracy for the clustered labels\n",
        "                            '''\n",
        "                            correct_txt_true_pred=[]\n",
        "                            def topps(n):\n",
        "                                            cc=0\n",
        "                                            vb1=0\n",
        "                                            for tt in txt_lbp:\n",
        "                                                    #if vb1 < 1000:\n",
        "                                                            #vb1=vb1+1 \n",
        "                                                            try:\n",
        "                                                                for vb in txt_lbp[tt][0:n]:\n",
        "                                                                        #print(rttext_tagh[tt][0],vb)\n",
        "                                                                        if vb in rttext_tagh[tt][0:n]:\n",
        "                                                                        #if str(vb) ==str(rttext_tagh[tt][0]):\n",
        "                                                                            cc=cc+1\n",
        "                                                                            if tt not in correct_txt_true_pred:\n",
        "                                                                                        correct_txt_true_pred.append(tt)\n",
        "                                                                            break\n",
        "                                                                        else:\n",
        "                                                                            continue\n",
        "\n",
        "                                                            except:\n",
        "                                                                continue\n",
        "                                                            \n",
        "                                            #txt_lbp\n",
        "                                            print(\"Top_\"+str(n)+ \" Prediction Score: \")\n",
        "                                            print(cc/len(txt_lbp))\n",
        "                                            ac=cc/len(txt_lbp)\n",
        "                                            return ac\n",
        "                            top=3\n",
        "                            scc=[]\n",
        "                            for zz in range(1,top+1):\n",
        "                                ac=topps(zz)\n",
        "                                scc.append(ac)\n",
        "                            return nmmm,scc,per_txt_nonori_score_avg,per_txt_ori_score_avg,correct_txt_true_pred,per_txt_ori_pred_rank_avg,per_txt_ori_ori_rank_avg\n",
        "                                \n",
        "                                \n",
        "\n",
        "            rand_acc={}\n",
        "            rand_pscr_nonlb={}\n",
        "            rand_pscr_orlb={}\n",
        "            rand_predi_rank_orlb={}\n",
        "            rand_ori_rank_orlb={}\n",
        "            correct_txt_true_p={}\n",
        "            count_percl_hosctxt={}\n",
        "            count_percl_txt={}\n",
        "            for tt11 in  final_clut2:\n",
        "                nmmm,scc,per_txt_nonori_score_avg,per_txt_ori_score_avg,correct_txt_true_pred,per_txt_ori_pred_rank_avg,per_txt_ori_ori_rank_avg=tagcls_only_cls()\n",
        "                rand_acc[tt11]=scc\n",
        "                rand_pscr_nonlb[tt11]=per_txt_nonori_score_avg\n",
        "                rand_pscr_orlb[tt11]=per_txt_ori_score_avg\n",
        "                correct_txt_true_p[tt11]=correct_txt_true_pred\n",
        "                rand_predi_rank_orlb[tt11]=per_txt_ori_pred_rank_avg\n",
        "                rand_ori_rank_orlb[tt11]=per_txt_ori_ori_rank_avg\n",
        "                count_percl_hosctxt[tt11]=nmmm\n",
        "                count_percl_txt[tt11]=len(final_clut2[tt11])\n",
        "                print(\"\\n\\n\")\n",
        "            return rand_acc,rand_pscr_nonlb,rand_pscr_orlb,rand_predi_rank_orlb,rand_ori_rank_orlb,count_percl_hosctxt,count_percl_txt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "s=[]\n",
        "b=[]\n",
        "noc=[]\n",
        "oc=[]\n",
        "\n",
        "for j in range(5,16,2):\n",
        "      print(\"cluster\"+str(j)+\"\\n\")\n",
        "      final_clut2,rttext_tagh1=labe_cl(j)\n",
        "      rand_acc,rand_pscr_nonlb,rand_pscr_orlb,rand_predi_rank_orlb,rand_ori_rank_orlb,count_percl_hosctxt,count_percl_txt=lb_txt_cl(final_clut2,rttext_tagh1)\n",
        "      vr_t1=[]\n",
        "      vr_t2=[]\n",
        "      vr_t3=[]\n",
        "      for kk in rand_acc:\n",
        "            vr_t1.append(rand_acc[kk][0])\n",
        "            vr_t2.append(rand_acc[kk][1])\n",
        "            vr_t3.append(rand_acc[kk][2])\n",
        "      non=[]\n",
        "      for vv in rand_pscr_nonlb:\n",
        "          s1=0\n",
        "          for kk in rand_pscr_nonlb[vv]:\n",
        "              #s1=0\n",
        "              #for tx in rand_pscr_nonlb[vv][kk]:\n",
        "              s1=s1+rand_pscr_nonlb[vv][kk]\n",
        "          sv=s1/len(rand_pscr_nonlb[vv])\n",
        "          non.append(sv)\n",
        "      sv1=mean(non)\n",
        "      noc.append(sv1)\n",
        "      on=[]\n",
        "      for vv in rand_pscr_orlb:\n",
        "          s5=0\n",
        "          for kk in rand_pscr_orlb[vv]:\n",
        "              #s11=0\n",
        "              #for tx in rand_pscr_orlb[vv][kk]:\n",
        "                  s5=s5+rand_pscr_orlb[vv][kk]\n",
        "          sv2=s5/len(rand_pscr_orlb[vv])\n",
        "          on.append(sv2)\n",
        "      sv3=mean(on)\n",
        "      oc.append(sv3)\n",
        "\n",
        "\n",
        "      vb1=mean(vr_t1)\n",
        "      s.append(vb1)\n",
        "      vb2=mean(vr_t2)\n",
        "      b.append(vb2)\n",
        "        \n",
        "\n",
        "# Drawing Varying the cluster of the class labels  keeping the clusters of texts fixed to 40\n",
        "\n",
        "\n",
        "\n",
        "#vr_t1=s\n",
        "#vr_t2=b\n",
        "\n",
        "\n",
        "'''\n",
        "Accuracy\n",
        "'''\n",
        "\n",
        "\n",
        "#Geb_b30 = nri#[11, 10, 12, 14, 16, 19, 17, 14, 18, 17]\n",
        "#years_b30 = range(0,len(nri))\n",
        "#Geb_a30 = ori#[12, 10, 13, 14, 12, 13, 18, 16,0,0]\n",
        "#years_a30 = range(0,len(ori))\n",
        "#print(len(vr_t1))\n",
        "years_a31 = range(5,16,2)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(years_a31, s, label='Top-1', color='blue')\n",
        "ax.plot(years_a31,b, label='Top-2', color = 'red')\n",
        "#ax.plot(years_a31,vr_t3, label='Top-3', color = 'green')\n",
        "legend = ax.legend(loc='lower right', fontsize='x-large')\n",
        "plt.xlabel('Varying the number of Clusters of the Class labels')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(' Top-K (K=1,2) accuracy scores')\n",
        "plt.show()\n",
        "plt.savefig(\"Variation_cluster_labels.pdf\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tgDpLdxA_P5L"
      },
      "outputs": [],
      "source": [
        "# Average score of non-original and original  varying cluster  of classes\n",
        "\n",
        "years_a31 = range(5,16,2)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(years_a31,noc, label='Non-Oroginal Class', color='blue')\n",
        "ax.plot(years_a31,oc, label='Original Class', color = 'red')\n",
        "#ax.plot(years_a31,vr_t3, label='Top-3', color = 'green')\n",
        "legend = ax.legend(loc='lower right', fontsize='x-large')\n",
        "plt.xlabel('Varying the number of Clusters of the Class labels')\n",
        "plt.ylabel('Average Probability Score')\n",
        "plt.title(' Comparison of Original Class and Non-Original Class Concerning Average Probability Score')\n",
        "plt.show()\n",
        "plt.savefig(\"Variation_cluster_labels_probability score.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yU4JKIZkWs3b"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NZyXvax8WtkE"
      },
      "source": [
        "# Here we have varied the number of clusters of the texts keeping the number of clusters of the class labels fixed. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "QNfoBZ-f_QBb",
        "outputId": "c879377f-e0f8-47b0-bea5-c20915d83206"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cluster 6\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3\n",
            "Cluster: 0\n",
            "3 100\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "96 100\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.96\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "2\n",
            "Top_1 Prediction Score: \n",
            "0.96\n",
            "Top_2 Prediction Score: \n",
            "0.99\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 1\n",
            "3 100\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "93 100\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.93\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "2\n",
            "Top_1 Prediction Score: \n",
            "0.93\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cluster: 2\n",
            "3 100\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "4 100\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.04\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "59\n",
            "Top_1 Prediction Score: \n",
            "0.04\n",
            "Top_2 Prediction Score: \n",
            "0.97\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "cluster 5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5\n",
            "Cluster: 0\n",
            "2 100\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "95 100\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.95\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "4\n",
            "Top_1 Prediction Score: \n",
            "0.95\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 1\n",
            "3 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "93 100\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.93\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "2\n",
            "Top_1 Prediction Score: \n",
            "0.93\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 2\n",
            "3 100\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "4 100\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.04\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "52\n",
            "Top_1 Prediction Score: \n",
            "0.04\n",
            "Top_2 Prediction Score: \n",
            "0.97\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 3\n",
            "1 48"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "48 48\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 4\n",
            "3 100\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "98 100\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.98\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "2\n",
            "Top_1 Prediction Score: \n",
            "0.98\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "cluster 4\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "Cluster: 0\n",
            "3 100\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "91 100\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.91\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "6\n",
            "Top_1 Prediction Score: \n",
            "0.91\n",
            "Top_2 Prediction Score: \n",
            "0.96\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 1\n",
            "3 100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "19 100\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.19\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "49\n",
            "Top_1 Prediction Score: \n",
            "0.19\n",
            "Top_2 Prediction Score: \n",
            "0.97\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 2\n",
            "3 100\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "7 100\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.07\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "44\n",
            "Top_1 Prediction Score: \n",
            "0.07\n",
            "Top_2 Prediction Score: \n",
            "0.92\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 3\n",
            "2 100\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "87 100\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.87\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "9\n",
            "Top_1 Prediction Score: \n",
            "0.87\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 4\n",
            "1 48\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "48 48\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 5\n",
            "3 100\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "98 100\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.98\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "2\n",
            "Top_1 Prediction Score: \n",
            "0.98\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 6\n",
            "1 41\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "41 41\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 7\n",
            "2 98\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "11 98\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.11224489795918367\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "26\n",
            "Top_1 Prediction Score: \n",
            "0.11224489795918367\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 8\n",
            "1 63\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "63 63\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "cluster 3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17\n",
            "Cluster: 0\n",
            "3 90\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "82 90\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.9111111111111111\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "6\n",
            "Top_1 Prediction Score: \n",
            "0.9111111111111111\n",
            "Top_2 Prediction Score: \n",
            "0.9666666666666667\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 1\n",
            "2 78\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "22 78\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.28205128205128205\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "20\n",
            "Top_1 Prediction Score: \n",
            "0.28205128205128205\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 2\n",
            "2 75\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "8 75\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.10666666666666667\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "34\n",
            "Top_1 Prediction Score: \n",
            "0.10666666666666667\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 3\n",
            "1 11\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "11 11\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cluster: 4\n",
            "1 48\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "48 48\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 5\n",
            "3 65\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "4 65\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.06153846153846154\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "46\n",
            "Top_1 Prediction Score: \n",
            "0.06153846153846154\n",
            "Top_2 Prediction Score: \n",
            "0.9692307692307692\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 6\n",
            "3 77\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "75 77\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.974025974025974\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "2\n",
            "Top_1 Prediction Score: \n",
            "0.974025974025974\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 7\n",
            "1 41\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "41 41\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 8\n",
            "2 30\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "7 30\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.23333333333333334\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "21\n",
            "Top_1 Prediction Score: \n",
            "0.23333333333333334\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 9\n",
            "2 57\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "50 57\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.8771929824561403\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "4\n",
            "Top_1 Prediction Score: \n",
            "0.8771929824561403\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 10\n",
            "3 87\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "83 87\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.9540229885057471\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "3\n",
            "Top_1 Prediction Score: \n",
            "0.9540229885057471\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 11\n",
            "2 78\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "11 78\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.14102564102564102\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "12\n",
            "Top_1 Prediction Score: \n",
            "0.14102564102564102\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 12\n",
            "1 63\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "63 63\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 13\n",
            "1 21\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "21 21\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 14\n",
            "2 57\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "50 57\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.8771929824561403\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "3\n",
            "Top_1 Prediction Score: \n",
            "0.8771929824561403\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 15\n",
            "1 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "20 20\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 16\n",
            "1 52\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "52 52\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "cluster 2\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "45\n",
            "Cluster: 0\n",
            "1 20\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "20 20\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 1\n",
            "2 32\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "9 32\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.28125\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "13\n",
            "Top_1 Prediction Score: \n",
            "0.28125\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 2\n",
            "2 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "4 29\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.13793103448275862\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "14\n",
            "Top_1 Prediction Score: \n",
            "0.13793103448275862\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 3\n",
            "1 11\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "11 11\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 4\n",
            "1 39\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "39 39\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 5\n",
            "1 30\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "30 30\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cluster: 6\n",
            "2 24\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "21 24\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.875\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "3\n",
            "Top_1 Prediction Score: \n",
            "0.875\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 7\n",
            "1 38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "38 38\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 8\n",
            "3 33\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "31 33\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.9393939393939394\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "2\n",
            "Top_1 Prediction Score: \n",
            "0.9393939393939394\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 9\n",
            "3 35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "2 35\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.05714285714285714\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "29\n",
            "Top_1 Prediction Score: \n",
            "0.05714285714285714\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 10\n",
            "1 11\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "11 11\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 11\n",
            "2 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "7 30\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.23333333333333334\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "21\n",
            "Top_1 Prediction Score: \n",
            "0.23333333333333334\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 12\n",
            "1 29\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "29 29\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 13\n",
            "1 17\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "17 17\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 14\n",
            "1 24\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "24 24\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 15\n",
            "3 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "23 26\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.8846153846153846\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "2\n",
            "Top_1 Prediction Score: \n",
            "0.8846153846153846\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 16\n",
            "2 38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "7 38\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.18421052631578946\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "11\n",
            "Top_1 Prediction Score: \n",
            "0.18421052631578946\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 17\n",
            "2 28\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "22 28\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.7857142857142857\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "4\n",
            "Top_1 Prediction Score: \n",
            "0.7857142857142857\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 18\n",
            "2 17\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "4 17\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.23529411764705882\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "5\n",
            "Top_1 Prediction Score: \n",
            "0.23529411764705882\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 19\n",
            "1 20\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "20 20\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 20\n",
            "1 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "12 12\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 21\n",
            "1 23\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "23 23\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 22\n",
            "1 21\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "21 21\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 23\n",
            "1 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "9 9\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 24\n",
            "1 12\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "12 12\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cluster: 25\n",
            "1 17\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "17 17\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 26\n",
            "1 23\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "23 23\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 27\n",
            "1 20\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "20 20\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 28\n",
            "1 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "15 15\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 29\n",
            "1 7\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "7 7\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 30\n",
            "1 "
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "40\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "40 40\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 31\n",
            "1 33\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "33 33\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 32\n",
            "1 10\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "10 10\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 33\n",
            "1 20\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "20 20\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 34\n",
            "1 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "11 11\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 35\n",
            "3 26\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "23 26\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.8846153846153846\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "1\n",
            "Top_1 Prediction Score: \n",
            "0.8846153846153846\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 36\n",
            "1 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "9 9\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 37\n",
            "1 8\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "8 8\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 38\n",
            "1 30\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "30 30\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 39\n",
            "1 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "8 8\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 40\n",
            "1 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "10 10\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 41\n",
            "2 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "10 16\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.625\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "3\n",
            "Top_1 Prediction Score: \n",
            "0.625\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 42\n",
            "1 9\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "9 9\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 43\n",
            "1 22\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "22 22\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 44\n",
            "1 8\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "8 8\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "cluster 1\n",
            "\n",
            "30\n",
            "Cluster: 0\n",
            "1 7\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "7 7\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 1\n",
            "1"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " 16\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "16 16\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 2\n",
            "1 6\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "6 6\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cluster: 3\n",
            "1 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "7 7\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 4\n",
            "1 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "8 8\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 5\n",
            "1 6\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "6 6\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 6\n",
            "1 10\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "10 10\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 7\n",
            "1 13\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "13 13\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 8\n",
            "1 6\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "6 6\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 9\n",
            "3 6\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "5 6\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.8333333333333334\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "1\n",
            "Top_1 Prediction Score: \n",
            "0.8333333333333334\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 10\n",
            "1 8\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "8 8\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 11\n",
            "1 7\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "7 7\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 12\n",
            "2 8\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "5 8\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "0.625\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "3\n",
            "Top_1 Prediction Score: \n",
            "0.625\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 13\n",
            "1 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "7 7\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 14\n",
            "1 7\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "7 7\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Cluster: 15\n",
            "1 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "8 8\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 16\n",
            "1 6\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "6 6\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 17\n",
            "1 6\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "6 6\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 18\n",
            "1 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "8 8\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 19\n",
            "1 8\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "8 8\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 20\n",
            "1 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "6 6\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 21\n",
            "1 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of texts where the position of the original labels preserved after prediction\n",
            "6 6\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 22\n",
            "1 7\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "7 7\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 23\n",
            "1 8\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "8 8\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 24\n",
            "1 13\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "13 13\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 25\n",
            "1 6\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "6 6\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 26\n",
            "1 6\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "6 6\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\n",
            "Cluster: 27\n",
            "1 9\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "9 9\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n",
            "No model was supplied, defaulted to facebook/bart-large-mnli (https://huggingface.co/facebook/bart-large-mnli)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1 7\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "7 7\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n",
            "Cluster: 29\n",
            "1 6\n",
            "Number of texts where the position of the original labels preserved after prediction\n",
            "6 6\n",
            "Percentage of texts where the position of the original labels preserved after prediction\n",
            "1.0\n",
            "Number of non-original labels have higher prediction acores than original labels after prediction\n",
            "0\n",
            "Top_1 Prediction Score: \n",
            "1.0\n",
            "Top_2 Prediction Score: \n",
            "1.0\n",
            "Top_3 Prediction Score: \n",
            "1.0\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "#Tag Clustering using Agglomerative and K-medoids Clustering  (clustering texts in data)\n",
        "import sys\n",
        "import matplotlib.pyplot as plt\n",
        "from numpy.ma.core import mean\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "import sys\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import numpy as np\n",
        "import operator\n",
        "from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
        "import sys\n",
        "from scipy import spatial\n",
        "from sklearn_extra.cluster import KMedoids\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
        "import math\n",
        "import sys\n",
        "import random\n",
        "import operator\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import numpy as np\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "import numpy as np\n",
        "from scipy import spatial\n",
        "\n",
        "\n",
        "\n",
        "def labe_cl(n):\n",
        "            #Unique Tag list\n",
        "            embedder = SentenceTransformer('all-MiniLM-L12-v2')\n",
        "            tagu=[]\n",
        "            tagu1=[]\n",
        "            stt=[]\n",
        "            sent=[]\n",
        "            relation_sent=[]\n",
        "            for  sz in rttext_tag2:\n",
        "                    s=''\n",
        "                    gh=[]\n",
        "                    for vb in rttext_tag2[sz]:\n",
        "                        #if vb not in stt:\n",
        "                            # s=str(vb)+\" \"+sz\n",
        "                            #if vb not in tagu1:\n",
        "                                #gh.append(vb)\n",
        "                                #tagu1.append(vb)\n",
        "                            #gh.append(sz)\n",
        "                            s=s+str(vb)+\" \"+str(sz)+\" \"\n",
        "                            relation_sent.append(s)\n",
        "                            if vb not in gh:\n",
        "                                    gh.append(vb)\n",
        "                            if vb not in stt:\n",
        "                                    stt.append(vb)\n",
        "                            vb1=sz.split()\n",
        "                            for zx in vb1:\n",
        "                                    if zx not in gh:\n",
        "                                        gh.append(zx)\n",
        "                            sent.append(gh)\n",
        "                            \n",
        "            ds=set(stt)\n",
        "            for kk in ds:\n",
        "                tagu.append(kk)\n",
        "           # print(len(tagu))\n",
        "            for tt in tagu:\n",
        "                pass\n",
        "\n",
        "            corpus =tagu#tagss# tagu\n",
        "            crp_txt={}\n",
        "            corpus_embeddings = embedder.encode(corpus)\n",
        "            for sentence, embedding in zip(tagu, corpus_embeddings):\n",
        "                lst=embedding.tolist()\n",
        "                crp_txt[sentence]=lst\n",
        "            vectorizer = TfidfVectorizer()\n",
        "            X = vectorizer.fit_transform(corpus)\n",
        "\n",
        "            num_clusters=5 #{random, heuristic, k-medoids++, build\n",
        "            kmedoids = KMedoids(n_clusters=5,metric='cosine', method='alternate',init='k-medoids++', max_iter=500000, random_state=1).fit(X)\n",
        "            cluster_assignment,cn=kmedoids.labels_,kmedoids.cluster_centers_\n",
        "\n",
        "            clustered_sentences = {}\n",
        "            clustered_sentences1 = {}\n",
        "            for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
        "                if cluster_id not in clustered_sentences:\n",
        "                    clustered_sentences[cluster_id] = []\n",
        "                    clustered_sentences1[cluster_id] = []\n",
        "                if corpus[sentence_id] in tagu:\n",
        "                        clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
        "                if len(vectorizer.inverse_transform(cn[cluster_id])[0])==2:\n",
        "                    gh=str(vectorizer.inverse_transform(cn[cluster_id])[0][0])+\"-\"+str(vectorizer.inverse_transform(cn[cluster_id])[0][1])\n",
        "                \n",
        "                    if gh not in clustered_sentences1[cluster_id]:\n",
        "                        clustered_sentences1[cluster_id].append(gh)\n",
        "                    \n",
        "                if len(vectorizer.inverse_transform(cn[cluster_id])[0])==1:\n",
        "                    for vv in vectorizer.inverse_transform(cn[cluster_id])[0]:\n",
        "                        if vv not in clustered_sentences1[cluster_id]:\n",
        "                                clustered_sentences1[cluster_id].append(vv)\n",
        "                    \n",
        "            final_clut1=clustered_sentences\n",
        "\n",
        "\n",
        "            final_cluh={}\n",
        "            for kk in final_clut1:\n",
        "                    final_cluh[kk]=clustered_sentences1[kk]\n",
        "            '''\n",
        "            final_cluh={}\n",
        "            for kk in final_clut1:\n",
        "                gh=[]\n",
        "                if len(final_clut1[kk])%2==0:\n",
        "                        pp=len(final_clut1[kk])//2\n",
        "                        #gh.append(final_clut1[kk][pp-1])\n",
        "                        gh.append(final_clut1[kk][pp])\n",
        "                        final_cluh[kk]=gh         \n",
        "                elif len(final_clut1[kk])%2!=0:\n",
        "                        pp=len(final_clut1[kk])//2\n",
        "                        gh.append(final_clut1[kk][pp])\n",
        "                        final_cluh[kk]=gh\n",
        "\n",
        "            '''\n",
        "            for t in final_clut1:\n",
        "               pass# print(final_cluh[t])\n",
        "            #Re-assigning the labels \n",
        "\n",
        "            embedder = SentenceTransformer('all-MiniLM-L12-v2')\n",
        "\n",
        "\n",
        "            #final_cluh={}\n",
        "            rttext_tagh1={}\n",
        "            rttext_tagh={}\n",
        "            cc=0\n",
        "            mptxt={}\n",
        "            rttag={}\n",
        "            allid=[]\n",
        "            truhh=[]\n",
        "            vbb=[]\n",
        "\n",
        "            from sklearn.metrics.pairwise import cosine_similarity,cosine_distances\n",
        "            import numpy as np\n",
        "            for kk in final_clut1:\n",
        "                for vz in rttext_tag2:\n",
        "                    ggh=[]\n",
        "                    ggh0=[]\n",
        "                    ggh1=[]\n",
        "                    ggh11=[]\n",
        "                    ggh111=[]\n",
        "                    c=0\n",
        "                    #corpus_embeddings = embedder.encode(vz)\n",
        "                    for zx in rttext_tag2[vz]:\n",
        "                        if zx in final_clut1[kk]:\n",
        "                            for vb3 in final_cluh[kk]:\n",
        "                                #if vb3 in sametopic_rl:\n",
        "                                    #if vz in sametopic_rl[vb3]:\n",
        "                                            if vb3 not in ggh:\n",
        "                                                ggh.append(vb3)\n",
        "                                    #else:\n",
        "                                        #continue\n",
        "                            if len(ggh)>0:\n",
        "                                rttext_tagh1[vz]=ggh\n",
        "                            break\n",
        "                        else:\n",
        "                            continue\n",
        "                    \n",
        "\n",
        "            jj=[]\n",
        "            for vv in rttext_tagh1:\n",
        "                for jk in rttext_tagh1[vv]:\n",
        "                    if jk not in jj:\n",
        "                        jj.append(jk)\n",
        "            #print(len(jj),len(rttext_tagh1))\n",
        "            # Clustering the text with pre-processed labels\n",
        "            snt=[]\n",
        "            rttext_tagh={}\n",
        "\n",
        "\n",
        "            truhh=[]\n",
        "            for jj in rttext_tagh1:\n",
        "                snt.append(jj)\n",
        "\n",
        "\n",
        "\n",
        "            embedder = SentenceTransformer('all-MiniLM-L12-v2')#('all-distilroberta-v1')#('all-MiniLM-L12-v2')#('all-distilroberta-v1')#('all-MiniLM-L12-v2')\n",
        "            # Corpus with example sentences\n",
        "            corpus = snt\n",
        "            corpus_embeddings = embedder.encode(corpus)\n",
        "\n",
        "            #num_clusters = 10\n",
        "\n",
        "            # Normalize the embeddings to unit length\n",
        "            corpus_embeddings = corpus_embeddings /  np.linalg.norm(corpus_embeddings, axis=1, keepdims=True)\n",
        "\n",
        "            # Perform Agglomerative clustering\n",
        "            clustering_model = AgglomerativeClustering(n_clusters=None,distance_threshold=n) #, affinity='cosine', linkage='average', distance_threshold=0.4)\n",
        "            clustering_model.fit(corpus_embeddings)\n",
        "            cluster_assignment,dis = clustering_model.labels_,clustering_model.distances_\n",
        "            #print(dis)\n",
        "            clustered_sentences = {}\n",
        "            for sentence_id, cluster_id in enumerate(cluster_assignment):\n",
        "                if cluster_id not in clustered_sentences:\n",
        "                    clustered_sentences[cluster_id] = []\n",
        "\n",
        "                clustered_sentences[cluster_id].append(corpus[sentence_id])\n",
        "            final_clut11={}\n",
        "\n",
        "            for i, cluster in clustered_sentences.items():\n",
        "                cls=[]\n",
        "                vc=0\n",
        "                #f len(cluster)>=10:\n",
        "                for kk in cluster:\n",
        "                 if vc<100:\n",
        "                    if kk not in cls:\n",
        "                        cls.append(kk)\n",
        "                        vc=vc+1\n",
        "                final_clut11[i]=cls\n",
        "                #print(cluster[0])\n",
        "\n",
        "                #print(\"Cluster \", i+1)\n",
        "                #print(cluster)\n",
        "                #print(\"\")\n",
        "            cln=0\n",
        "            final_clut2={}\n",
        "\n",
        "            for tt in final_clut11:  \n",
        "                    if len(final_clut11[tt])>=6:\n",
        "                    \n",
        "                            final_clut2[cln]=final_clut11[tt]\n",
        "                            cln=cln+1\n",
        "                        # vc=vc+1\n",
        "            print(len(final_clut2))\n",
        "            return final_clut2,rttext_tagh1\n",
        "\n",
        "\n",
        "#Clusteredtext with pre-processed labels\n",
        "import random   \n",
        "def lb_txt_cl(final_clut2,rttext_tagh1):\n",
        "            test={}\n",
        "            def tagcls_only_cls():\n",
        "                            rttext_tagh={}     \n",
        "                            truhh=[]  \n",
        "                            #tt=random.randint(0,len(final_clut2)-1)\n",
        "\n",
        "                            for vv in final_clut2[tt11]:\n",
        "                                                if vv not in rttext_tagh:\n",
        "                                                    rttext_tagh[vv]=rttext_tagh1[vv]\n",
        "                            tr=[]\n",
        "                            for tt in rttext_tagh:\n",
        "                                #print(rttext_tagh[tt][0])\n",
        "                                if rttext_tagh[tt][0] not in tr:\n",
        "                                    tr.append(rttext_tagh[tt][0])\n",
        "                            s=set(tr)\n",
        "                            for bb in s:\n",
        "                                truhh.append(bb)\n",
        "                            print(\"Cluster: \"+str(tt11))\n",
        "                            print(len(truhh),len(rttext_tagh))\n",
        "\n",
        "                            #Accuracy Computation\n",
        "\n",
        "                            #multi tag\n",
        "\n",
        "                            from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "                            import numpy as np\n",
        "                            import operator\n",
        "                            import matplotlib.pyplot as plt\n",
        "                            from transformers import pipeline\n",
        "                            from pylab import rcParams\n",
        "                            import sys \n",
        "                            import nltk\n",
        "                            import re\n",
        "                            import operator\n",
        "                            #from transformers_interpret import ZeroShotClassificationExplainer\n",
        "                            zero_shot_classifier = pipeline(\"zero-shot-classification\")#,model='roberta-large-mnli')#model='facebook/bart-large-mnli')#,model='Recognai/zeroshot_selectra_medium')#,model='facebook/bart-large-mnli')\n",
        "                            #tokenizer = AutoTokenizer.from_pretrained(\"Recognai/zeroshot_selectra_medium\")#(\"facebook/bart-base-mnli\")#(\"Recognai/zeroshot_selectra_medium\")\n",
        "                            #model = AutoModelForSequenceClassification.from_pretrained(\"Recognai/zeroshot_selectra_medium\")#(\"facebook/bart-base-mnli\")#(\"Recognai/zeroshot_selectra_medium\")\n",
        "                            #zero_shot_explainer = ZeroShotClassificationExplainer(model, tokenizer)\n",
        "                            cn=0\n",
        "                            txt_lbp={}\n",
        "                            ocl_di={}\n",
        "                            pred_l={}\n",
        "                            ocl_dia={}\n",
        "                            pred_lnk={}\n",
        "                            ocl_dnk={}\n",
        "                            pred_tk={}\n",
        "                            ocl_tk={}\n",
        "                            all_txt_label_score={}\n",
        "                            all_txt_label_rank={}\n",
        "\n",
        "                            # Zero-shot Classification\n",
        "                            def review_explain(text):\n",
        "                                    result = zero_shot_classifier(sequences =text,candidate_labels =truhh ,multi_label=True)\n",
        "                                    \n",
        "                                    return result['labels'],result['scores']\n",
        "\n",
        "                            for tt in rttext_tagh:\n",
        "                                mpd={}\n",
        "                                nlb=[]\n",
        "                                mpd_nk={}\n",
        "                                mpd_tk={}\n",
        "                                nlb_tk=[]\n",
        "                                nlb_nk=[]\n",
        "                                rn={}\n",
        "                                rsc={}\n",
        "                                clas,score= review_explain(tt)\n",
        "                            \n",
        "                                for bb in range(0,len(clas)):\n",
        "                                    rsc[clas[bb]]=score[bb]\n",
        "                                for bb in range(0,len(clas)):\n",
        "                                    rn[clas[bb]]=bb+1\n",
        "                                all_txt_label_score[tt]=rsc\n",
        "                                all_txt_label_rank[tt]=rn\n",
        "                                for k1 in rttext_tagh[tt]:\n",
        "                                        for t3 in range(0,len(clas)):\n",
        "                                            if str(clas[t3])==str(k1):\n",
        "                                                mpd[k1]=score[t3]\n",
        "                                for k1 in rttext_tagh[tt]:\n",
        "                                        for t3 in range(0,len(clas)):\n",
        "                                            if str(clas[t3])!=str(k1):\n",
        "                                                if score[t3]>0.5:\n",
        "                                                    mpd_nk[k1]=score[t3]\n",
        "                                for k1 in rttext_tagh[tt]:\n",
        "                                        for t3 in range(0,len(clas)):\n",
        "                                            if str(clas[t3])==str(k1):\n",
        "                                                if score[t3]>0.5:\n",
        "                                                    mpd_tk[k1]=score[t3]\n",
        "                                \n",
        "                                dd=sorted(mpd.items(), key=operator.itemgetter(1),reverse=True)\n",
        "                                dd1=sorted(mpd_nk.items(), key=operator.itemgetter(1),reverse=True)\n",
        "                                dd2=sorted(mpd_tk.items(), key=operator.itemgetter(1),reverse=True)\n",
        "                                \n",
        "                                for zz in dd:\n",
        "                                    nlb.append(zz[0])\n",
        "                                for zz1 in dd1:\n",
        "                                    nlb_nk.append(zz1[0])\n",
        "                                for zz2 in dd2:\n",
        "                                    nlb_tk.append(zz2[0])\n",
        "                                \n",
        "                                pred_lnk[tt]=nlb_nk #ranked list of the non-original labels has pribability greater than 50%\n",
        "                                pred_tk[tt]=nlb_tk#ranked list of the original labels has pribability greater than and equal 90% and appear in top N labels\n",
        "                                ocl_di[tt]=nlb[0:1]#single label with the highest score of the original label\n",
        "                                ocl_dia[tt]=nlb#ranked list of the original label\n",
        "                                \n",
        "\n",
        "                                txt_lbp[tt]=clas[0:10]\n",
        "                                pred_l[tt]=clas\n",
        "                                #test[tt11]=\n",
        "\n",
        "                            '''\n",
        "                            Comparing average rank of the predicted original labels with that of it ideal rank positon\n",
        "                            Coounting the number of non-original labels that have higher probability scores than that of original labels per text\n",
        "\n",
        "                            '''\n",
        "                            # average rank\n",
        "                            ccc=0\n",
        "                            KK=3 # number of top predicted non-original labels\n",
        "\n",
        "                            per_txt_ori_rank_cmp={}\n",
        "                            per_txt_ori_score_avg={}\n",
        "                            per_txt_nonori_rank_cmp={}\n",
        "                            per_txt_nonori_pred_rank_avg={}\n",
        "                            per_txt_nonori_ori_rank_avg={}\n",
        "                            per_txt_nonori_score_avg={}\n",
        "                            per_txt_ori_pred_rank_avg={}\n",
        "                            per_txt_ori_ori_rank_avg={}\n",
        "                            per_txt_nonori_top_n={}\n",
        "\n",
        "\n",
        "                            for v in all_txt_label_score:\n",
        "                            #if v in rttext_tagh:\n",
        "                                orn=(len(rttext_tagh[v])+1)/2 # Ideal average rank position\n",
        "                                s=0\n",
        "                                sc=0\n",
        "                                cz=0\n",
        "                                nr=[]\n",
        "                                sno=0\n",
        "                                snosc=0\n",
        "                                for kz in all_txt_label_rank[v]:\n",
        "                                    if kz not in rttext_tagh[v]:\n",
        "                                        if cz<KK:\n",
        "                                                if kz not in nr:\n",
        "                                                        nr.append(kz)\n",
        "                                                        #print(kz,rttext_tagu[v],all_txt_label_rank[v][kz],all_txt_label_score[v][kz])\n",
        "                                                        sno=sno+float(all_txt_label_rank[v][kz])\n",
        "                                                        snosc=snosc+float(all_txt_label_score[v][kz])\n",
        "                                                        cz=cz+1\n",
        "                                #print(\"\\n\")\n",
        "                                per_txt_nonori_top_n[v]=nr\n",
        "                                per_txt_nonori_rank_cmp[v]=sno/KK\n",
        "                                per_txt_nonori_score_avg[v]=snosc/KK\n",
        "\n",
        "                                for kz in all_txt_label_rank[v]:\n",
        "                                    if kz in rttext_tagh[v]:\n",
        "                                        s=s+float(all_txt_label_rank[v][kz])\n",
        "                                        sc=sc+float(all_txt_label_score[v][kz])\n",
        "                            \n",
        "                                prn=s/len(rttext_tagh[v])\n",
        "                                per_txt_ori_score_avg[v]=sc/len(rttext_tagh[v])\n",
        "                                per_txt_ori_pred_rank_avg[v]=prn\n",
        "                                per_txt_ori_ori_rank_avg[v]=orn\n",
        "                                #print(prn,orn)\n",
        "                                dif=abs(prn-orn)\n",
        "                                per_txt_ori_rank_cmp[v]=dif\n",
        "                                if dif<=0.0:\n",
        "                                    ccc=ccc+1\n",
        "                            print(\"Number of texts where the position of the original labels preserved after prediction\")\n",
        "                            print(ccc,len(txt_lbp))\n",
        "                            print(\"Percentage of texts where the position of the original labels preserved after prediction\")\n",
        "                            print(ccc/len(txt_lbp))\n",
        "\n",
        "\n",
        "                            # average scores\n",
        "\n",
        "                            vvv=0\n",
        "                            for jj in per_txt_ori_score_avg:\n",
        "                                if per_txt_nonori_score_avg[jj]>per_txt_ori_score_avg[jj]:\n",
        "                                            vvv=vvv+1\n",
        "\n",
        "                            print(\"Number of non-original labels have higher prediction acores than original labels after prediction\")\n",
        "                            nmmm=vvv     \n",
        "                            print(vvv)\n",
        "                            #if tt11==1:\n",
        "                            # for kk in txt_lbp:\n",
        "                                #  pass#print(kk,txt_lbp[kk],rttext_tagh[kk])\n",
        "\n",
        "                            '''\n",
        "                            Accuracy for the clustered labels\n",
        "                            '''\n",
        "                            correct_txt_true_pred=[]\n",
        "                            def topps(n):\n",
        "                                            cc=0\n",
        "                                            vb1=0\n",
        "                                            for tt in txt_lbp:\n",
        "                                                    #if vb1 < 1000:\n",
        "                                                            #vb1=vb1+1 \n",
        "                                                            try:\n",
        "                                                                for vb in txt_lbp[tt][0:n]:\n",
        "                                                                        #print(rttext_tagh[tt][0],vb)\n",
        "                                                                        if vb in rttext_tagh[tt][0:n]:\n",
        "                                                                        #if str(vb) ==str(rttext_tagh[tt][0]):\n",
        "                                                                            cc=cc+1\n",
        "                                                                            if tt not in correct_txt_true_pred:\n",
        "                                                                                        correct_txt_true_pred.append(tt)\n",
        "                                                                            break\n",
        "                                                                        else:\n",
        "                                                                            continue\n",
        "\n",
        "                                                            except:\n",
        "                                                                continue\n",
        "                                                            \n",
        "                                            #txt_lbp\n",
        "                                            print(\"Top_\"+str(n)+ \" Prediction Score: \")\n",
        "                                            print(cc/len(txt_lbp))\n",
        "                                            ac=cc/len(txt_lbp)\n",
        "                                            return ac\n",
        "                            top=3\n",
        "                            scc=[]\n",
        "                            for zz in range(1,top+1):\n",
        "                                ac=topps(zz)\n",
        "                                scc.append(ac)\n",
        "                            return nmmm,scc,per_txt_nonori_score_avg,per_txt_ori_score_avg,correct_txt_true_pred,per_txt_ori_pred_rank_avg,per_txt_ori_ori_rank_avg\n",
        "                                \n",
        "                                \n",
        "\n",
        "            rand_acc={}\n",
        "            rand_pscr_nonlb={}\n",
        "            rand_pscr_orlb={}\n",
        "            rand_predi_rank_orlb={}\n",
        "            rand_ori_rank_orlb={}\n",
        "            correct_txt_true_p={}\n",
        "            count_percl_hosctxt={}\n",
        "            count_percl_txt={}\n",
        "            for tt11 in  final_clut2:\n",
        "                nmmm,scc,per_txt_nonori_score_avg,per_txt_ori_score_avg,correct_txt_true_pred,per_txt_ori_pred_rank_avg,per_txt_ori_ori_rank_avg=tagcls_only_cls()\n",
        "                rand_acc[tt11]=scc\n",
        "                rand_pscr_nonlb[tt11]=per_txt_nonori_score_avg\n",
        "                rand_pscr_orlb[tt11]=per_txt_ori_score_avg\n",
        "                correct_txt_true_p[tt11]=correct_txt_true_pred\n",
        "                rand_predi_rank_orlb[tt11]=per_txt_ori_pred_rank_avg\n",
        "                rand_ori_rank_orlb[tt11]=per_txt_ori_ori_rank_avg\n",
        "                count_percl_hosctxt[tt11]=nmmm\n",
        "                count_percl_txt[tt11]=len(final_clut2[tt11])\n",
        "                print(\"\\n\\n\")\n",
        "            return rand_acc,rand_pscr_nonlb,rand_pscr_orlb,rand_predi_rank_orlb,rand_ori_rank_orlb,count_percl_hosctxt,count_percl_txt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "s0=[]\n",
        "b0=[]\n",
        "noc0=[]\n",
        "oc0=[]\n",
        "clsize=[]\n",
        "for j in range(6,0,-1):\n",
        "      print(\"cluster \"+str(j)+\"\\n\")\n",
        "      final_clut2,rttext_tagh1=labe_cl(j)\n",
        "      rand_acc,rand_pscr_nonlb,rand_pscr_orlb,rand_predi_rank_orlb,rand_ori_rank_orlb,count_percl_hosctxt,count_percl_txt=lb_txt_cl(final_clut2,rttext_tagh1)\n",
        "      vr_t1=[]\n",
        "      vr_t2=[]\n",
        "      vr_t3=[]\n",
        "      for kk in rand_acc:\n",
        "            vr_t1.append(rand_acc[kk][0])\n",
        "            vr_t2.append(rand_acc[kk][1])\n",
        "            vr_t3.append(rand_acc[kk][2])\n",
        "      non=[]\n",
        "      for vv in rand_pscr_nonlb:\n",
        "          s1=0\n",
        "          for kk in rand_pscr_nonlb[vv]:\n",
        "              #s1=0\n",
        "              #for tx in rand_pscr_nonlb[vv][kk]:\n",
        "              s1=s1+rand_pscr_nonlb[vv][kk]\n",
        "          sv=s1/len(rand_pscr_nonlb[vv])\n",
        "          non.append(sv)\n",
        "      sv1=mean(non)\n",
        "      noc0.append(sv1)\n",
        "      on=[]\n",
        "      for vv in rand_pscr_orlb:\n",
        "          s5=0\n",
        "          for kk in rand_pscr_orlb[vv]:\n",
        "              #s11=0\n",
        "              #for tx in rand_pscr_orlb[vv][kk]:\n",
        "                  s5=s5+rand_pscr_orlb[vv][kk]\n",
        "          sv2=s5/len(rand_pscr_orlb[vv])\n",
        "          on.append(sv2)\n",
        "      sv3=mean(on)\n",
        "      oc0.append(sv3)\n",
        "\n",
        "\n",
        "      vb1=mean(vr_t1)\n",
        "      s0.append(vb1)\n",
        "      vb2=mean(vr_t2)\n",
        "      b0.append(vb2)\n",
        "      clsize.append(len(final_clut2))\n",
        "        \n",
        "\n",
        "# Drawing Varying the cluster of the texts  keeping the clusters of class labels fixed to 5\n",
        "\n",
        "\n",
        "'''\n",
        "Accuracy\n",
        "'''\n",
        "\n",
        "\n",
        "#Geb_b30 = nri#[11, 10, 12, 14, 16, 19, 17, 14, 18, 17]\n",
        "#years_b30 = range(0,len(nri))\n",
        "#Geb_a30 = ori#[12, 10, 13, 14, 12, 13, 18, 16,0,0]\n",
        "#years_a30 = range(0,len(ori))\n",
        "#print(len(vr_t1))\n",
        "years_a31 = range(3,55,10)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(years_a31, s0, label='Top-1', color='blue')\n",
        "ax.plot(years_a31,b0, label='Top-2', color = 'red')\n",
        "#ax.plot(years_a31,vr_t3, label='Top-3', color = 'green')\n",
        "legend = ax.legend(loc='lower right', fontsize='x-large')\n",
        "plt.xlabel('Varying the number of Clusters of the Text Data')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title(' Top-K (K=1,2) accuracy scores')\n",
        "plt.show()\n",
        "plt.savefig(\"Variation_cluster_labels.pdf\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r29oqG5i_QKM"
      },
      "outputs": [],
      "source": [
        "# Average score of non-original and original  varying cluster of texts\n",
        "\n",
        "years_a31 = range(3,55,10)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(years_a31,noc0, label='Non-Oroginal Class', color='blue')\n",
        "ax.plot(years_a31,oc0, label='Original Class', color = 'red')\n",
        "#ax.plot(years_a31,vr_t3, label='Top-3', color = 'green')\n",
        "legend = ax.legend(loc='lower right', fontsize='x-large')\n",
        "plt.xlabel('Varying the number of Clusters of the Text Data')\n",
        "plt.ylabel('Average Probability Score')\n",
        "plt.title(' Comparison of Original Class and Non-Original Class Concerning Average Probability Score')\n",
        "plt.show()\n",
        "plt.savefig(\"Variation_cluster_labels_probability score.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CfRVyZRUkbRU",
        "outputId": "1b49b3e9-f5b7-441a-87bf-3936a2bfc2e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.6433333333333334, 0.78, 0.6813605442176871, 0.7304800837159116, 0.8694111302946843, 0.9819444444444445]\n",
            "[0.9866666666666667, 0.994, 0.9833333333333333, 0.9962292609351434, 1.0, 1.0]\n"
          ]
        }
      ],
      "source": [
        "print(s0)\n",
        "print(b0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDt4Gl9_XV4K"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHJc_WJYXV7T"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "svUjOWt8l_hX"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "Zero_Shot_Reuters_Data_Appliccation_.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "652ac484380344848a6b01c2fa53a3d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ac407ec0f24c4bf796d66c24f165fdbd",
              "IPY_MODEL_bbd6653298254629b44a406ccf3e5060",
              "IPY_MODEL_9b6a74b10f0e4426825e472d7822a0c6"
            ],
            "layout": "IPY_MODEL_e40178f8553b41d19989b256da9c12f9"
          }
        },
        "ac407ec0f24c4bf796d66c24f165fdbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_94317af58f4c44f29ca0c2c78e451712",
            "placeholder": "",
            "style": "IPY_MODEL_6c9e5ba2c3c54c3b9d2d641aa1f9d715",
            "value": "Downloading builder script: "
          }
        },
        "bbd6653298254629b44a406ccf3e5060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_393b862585af465da9592e0a544eae17",
            "max": 4165,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c84ab686455c44e3a6dbdbd65a32c4b6",
            "value": 4165
          }
        },
        "9b6a74b10f0e4426825e472d7822a0c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_be2d87b3fb2946f699c68b668637b7a9",
            "placeholder": "",
            "style": "IPY_MODEL_2c504b12b8fc4a89941acc3a33389a31",
            "value": " 17.9k/? [00:00&lt;00:00, 613kB/s]"
          }
        },
        "e40178f8553b41d19989b256da9c12f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "94317af58f4c44f29ca0c2c78e451712": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c9e5ba2c3c54c3b9d2d641aa1f9d715": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "393b862585af465da9592e0a544eae17": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c84ab686455c44e3a6dbdbd65a32c4b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "be2d87b3fb2946f699c68b668637b7a9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c504b12b8fc4a89941acc3a33389a31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6cb81df58b143148db4176d980c12fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3b352707985f4dff9a66a97b002c3973",
              "IPY_MODEL_3e3e5dcb16a249b3b1464412df89ceb8",
              "IPY_MODEL_8c34e36d9414406898867bc3968951ed"
            ],
            "layout": "IPY_MODEL_e79f5a5b54e24d9e9283374f6a603fe7"
          }
        },
        "3b352707985f4dff9a66a97b002c3973": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_408d048a89e547818ee8d6fa10d0ac05",
            "placeholder": "",
            "style": "IPY_MODEL_ac5a86a33b9745279e09d6657edb826a",
            "value": "Downloading metadata: "
          }
        },
        "3e3e5dcb16a249b3b1464412df89ceb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_986976bf69f6455a80d1640d2a5729e3",
            "max": 2373,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5fe6a1a0fc2744faa0d706e4468bb652",
            "value": 2373
          }
        },
        "8c34e36d9414406898867bc3968951ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c1778f5c0c6f4649a0458bbad31feba7",
            "placeholder": "",
            "style": "IPY_MODEL_ff4565e1b760425bb81dd1b09881657f",
            "value": " 19.9k/? [00:00&lt;00:00, 749kB/s]"
          }
        },
        "e79f5a5b54e24d9e9283374f6a603fe7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "408d048a89e547818ee8d6fa10d0ac05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac5a86a33b9745279e09d6657edb826a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "986976bf69f6455a80d1640d2a5729e3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5fe6a1a0fc2744faa0d706e4468bb652": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c1778f5c0c6f4649a0458bbad31feba7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff4565e1b760425bb81dd1b09881657f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56c784471e634b979f00de1bff554610": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c6f21ef4f778496d8f6566ffc436852c",
              "IPY_MODEL_2abc2eacb8ce4523bdc9cd6a936ef1a4",
              "IPY_MODEL_b63a2d8d8bf34aff82774dc8eaec84a5"
            ],
            "layout": "IPY_MODEL_8b2741f3fc2f4137a09a77efd88888cf"
          }
        },
        "c6f21ef4f778496d8f6566ffc436852c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_913717e56f594b36ad999e0edd0ea827",
            "placeholder": "",
            "style": "IPY_MODEL_b997371f85e04791a48ba803df1812ec",
            "value": "Downloading data: 100%"
          }
        },
        "2abc2eacb8ce4523bdc9cd6a936ef1a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0066609e5e8e4612b31f6810100e35dd",
            "max": 8150596,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5a13bde675b34fbb82f3639648bf410f",
            "value": 8150596
          }
        },
        "b63a2d8d8bf34aff82774dc8eaec84a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_205de46e95fe49f9a441a42d51fe38b7",
            "placeholder": "",
            "style": "IPY_MODEL_2e45038cbad140ee888ab0354e233cbe",
            "value": " 8.15M/8.15M [00:00&lt;00:00, 12.9MB/s]"
          }
        },
        "8b2741f3fc2f4137a09a77efd88888cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "913717e56f594b36ad999e0edd0ea827": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b997371f85e04791a48ba803df1812ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0066609e5e8e4612b31f6810100e35dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a13bde675b34fbb82f3639648bf410f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "205de46e95fe49f9a441a42d51fe38b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e45038cbad140ee888ab0354e233cbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "41a0391bade84f6ba98b3df65e9703e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_08f3aa45f2fe47fb89824875f61d64b2",
              "IPY_MODEL_2152d97a76024bea802421eb3873b244",
              "IPY_MODEL_ed07b250f6944a5eb6921cc5ae16dbd2"
            ],
            "layout": "IPY_MODEL_c14776fd15d046c89bc7c8adc578387b"
          }
        },
        "08f3aa45f2fe47fb89824875f61d64b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b64c193c8e5c47759154fdde7a93e620",
            "placeholder": "",
            "style": "IPY_MODEL_b59943ec6a664dba966c0cd5d887aff3",
            "value": "Generating test split:  96%"
          }
        },
        "2152d97a76024bea802421eb3873b244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_86b2748dd5844bdea170edb37f978e8d",
            "max": 3299,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7c4998876d14184bb8c55d54ec36cf6",
            "value": 3299
          }
        },
        "ed07b250f6944a5eb6921cc5ae16dbd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a001fb3429f34d3cafa0feb0019713aa",
            "placeholder": "",
            "style": "IPY_MODEL_2d1e98ecea614c9daaf75f41f9eab1ae",
            "value": " 3176/3299 [00:01&lt;00:00, 3944.26 examples/s]"
          }
        },
        "c14776fd15d046c89bc7c8adc578387b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b64c193c8e5c47759154fdde7a93e620": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b59943ec6a664dba966c0cd5d887aff3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "86b2748dd5844bdea170edb37f978e8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7c4998876d14184bb8c55d54ec36cf6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a001fb3429f34d3cafa0feb0019713aa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2d1e98ecea614c9daaf75f41f9eab1ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f4cdfb52ff84cd79ae9507d912f6fb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ab557e8a521947688863f14c46435a97",
              "IPY_MODEL_df8ddaaca916442c8c58c7e064d0113d",
              "IPY_MODEL_94501ff6199048ef9311e6e9dbffef3c"
            ],
            "layout": "IPY_MODEL_113c5d858b4e43b3bd999c608849fec3"
          }
        },
        "ab557e8a521947688863f14c46435a97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_995f42023d0b44ce8ef5b78c72587b38",
            "placeholder": "",
            "style": "IPY_MODEL_f667f29fb62c4b758d1830d1f7630945",
            "value": "Generating train split:  98%"
          }
        },
        "df8ddaaca916442c8c58c7e064d0113d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_835c222f33794d91a868088942708611",
            "max": 9603,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_99af91501f6d43d89a1f89cff78e6ede",
            "value": 9603
          }
        },
        "94501ff6199048ef9311e6e9dbffef3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_100a8bd7175c4c64bd11a72f13cebee7",
            "placeholder": "",
            "style": "IPY_MODEL_1ec9d34cc0ab4f889b2b19c6e30a35ea",
            "value": " 9402/9603 [00:02&lt;00:00, 4749.19 examples/s]"
          }
        },
        "113c5d858b4e43b3bd999c608849fec3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "995f42023d0b44ce8ef5b78c72587b38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f667f29fb62c4b758d1830d1f7630945": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "835c222f33794d91a868088942708611": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "99af91501f6d43d89a1f89cff78e6ede": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "100a8bd7175c4c64bd11a72f13cebee7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ec9d34cc0ab4f889b2b19c6e30a35ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6b338d8aa4241d09890f0da7e6617b4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2a8e9e0049444da293208f3c13080c9a",
              "IPY_MODEL_435237f915b94d549c740db895a101ec",
              "IPY_MODEL_2222888c063a4295b9ca502bfee2bfcc"
            ],
            "layout": "IPY_MODEL_bce5481804084365a6ed873c6bf0b302"
          }
        },
        "2a8e9e0049444da293208f3c13080c9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_63f32c8cb2254759bd45d51a37db5c0c",
            "placeholder": "",
            "style": "IPY_MODEL_42cd1a1c412c4bd29e207de33e40f387",
            "value": "Generating unused split:  87%"
          }
        },
        "435237f915b94d549c740db895a101ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c3b4372cdbff4181b7b38317ef90e87b",
            "max": 722,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6aab97987dd94255b75f0fa2198b75a5",
            "value": 722
          }
        },
        "2222888c063a4295b9ca502bfee2bfcc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1c397df2a8a44b63bbdd5746d473f161",
            "placeholder": "",
            "style": "IPY_MODEL_7ea9f7871e28439f8b6cbece3bd4f8ff",
            "value": " 629/722 [00:00&lt;00:00, 1501.27 examples/s]"
          }
        },
        "bce5481804084365a6ed873c6bf0b302": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "63f32c8cb2254759bd45d51a37db5c0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42cd1a1c412c4bd29e207de33e40f387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3b4372cdbff4181b7b38317ef90e87b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6aab97987dd94255b75f0fa2198b75a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1c397df2a8a44b63bbdd5746d473f161": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ea9f7871e28439f8b6cbece3bd4f8ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15eb737e98e644aea0860430a87b89a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e750d2c0ac8b4f97af200bab5cb00a9f",
              "IPY_MODEL_405882e92b2d4c67a9ab73e7137ae0f4",
              "IPY_MODEL_7bb95a7a28a147ed9c5f6724087a1831"
            ],
            "layout": "IPY_MODEL_5c9e2c1ea5fd4e1f8662ed9b5c4294e4"
          }
        },
        "e750d2c0ac8b4f97af200bab5cb00a9f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c9f5650fbe48497f98f6466dafa0aacc",
            "placeholder": "",
            "style": "IPY_MODEL_10836d1772014617bae7c9f7167307dd",
            "value": "100%"
          }
        },
        "405882e92b2d4c67a9ab73e7137ae0f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6872183f31934ce9af84571ef3bc04df",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_42a2589c6b904374ba3cc147de8c7281",
            "value": 3
          }
        },
        "7bb95a7a28a147ed9c5f6724087a1831": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9ef344e7d5204825ac70ce5e33ccf3da",
            "placeholder": "",
            "style": "IPY_MODEL_8000ead497df4626a76ad71aadb7e31f",
            "value": " 3/3 [00:00&lt;00:00, 72.45it/s]"
          }
        },
        "5c9e2c1ea5fd4e1f8662ed9b5c4294e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9f5650fbe48497f98f6466dafa0aacc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "10836d1772014617bae7c9f7167307dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6872183f31934ce9af84571ef3bc04df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42a2589c6b904374ba3cc147de8c7281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9ef344e7d5204825ac70ce5e33ccf3da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8000ead497df4626a76ad71aadb7e31f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}